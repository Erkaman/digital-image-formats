\begin{comment}
  \bibliography{project.bib}
\end{comment}

\chapter{LZW}
\label{cha:lzw}

\begin{refsection}

  In this chapter, we will discuss the data compression algorithm LZW
  as it is described in
  \cite{nelson89:_lzw_data_compr,Welch:1984:THD:1319729.1320134,Salomon:2004:DCC}. We
  will first discuss the history behind the algorithm, then the
  compression algorithm itself, after this we will describe the
  decompression algorithm and in the end we will discuss the
  efficiency and compression ratio of this algorithm.

\section{The History Behind}

LZW stands for \textbf{L}empel, \textbf{Z}iv, \textbf{W}elch. Lempel
and Ziv are the two researches who developed the two compression
methods \lzseven and \lzeight. These two algorithms became the basis
for many other LZ variations, including LZMA \cite{palov11}, LZW and
LZSS \cite{Salomon:2004:DCC}. LZW is the variation that we will
discuss in this chapter. And finally, Welch is the guy the developed
this LZ variation.

\section{Description of the Compression algorithm}
\label{sec:lzw-comp-desc}

The LZW compression\index{LZW compression} algorithm is best
understood by walking through the LZW algorithm's process of
compressing some sample data.

In this example the algorithm is going to compress the sample data
\texttt{ababcbababaaaaaaa}.

Central to the entire algorithm's process is a string table. In this
table numbers called \textit{codes}\index{code} are assigned to
strings. The algorithm start by filling this string table with all the
strings that are possible to fit in a byte. That is, it adds all the
number codes 0-255 to the string table and these number codes are
assigned a one length string and this one length string consists of
the character that the number code represents in the current
encoding. For this example, we will use the character set ASCII
\cite{rfc20}, but really any character set could be used.

Table \ref{tab:str-tab-ascii} shows how this table ends up looking
like when it is filled.

\newcommand{\dotsrow}{\dots & \dots \\}
\newcommand{\strrow}[2]{$#1$ & #2 \\}

\begin{table}
  \centering
  \begin{tabular}{ll}
    \toprule
    Code & String\\
    \midrule

    \dotsrow
    \strrow{33}{!}
    \strrow{34}{"}
    \strrow{35}{\#}
    \dotsrow
    \strrow{97}{a}
    \strrow{98}{b}
    \strrow{99}{c}
    \strrow{100}{d}
    \strrow{101}{e}
    \dotsrow
    \strrow{255}{}

    \bottomrule
  \end{tabular}
  \caption{The initial LZW string table, filled with all the ASCII
    characters.}
  \label{tab:str-tab-ascii}
\end{table}

%\newcommand*{\newcode}[1]{%
%  \expandafter\newcommand\csname#1\endcsname c[1][]{\texttt{#1}##1\xspace}}

%\newcode{a}
\newcommand{\acode}{\texttt{a}\xspace}
\newcommand{\bcode}{\texttt{b}\xspace}
\newcommand{\ccode}{\texttt{c}\xspace}
\newcommand{\abcode}{\texttt{ab}\xspace}
\newcommand{\bacode}{\texttt{ba}\xspace}
\newcommand{\abccode}{\texttt{abc}\xspace}

Now the algorithm actually start going through the sample
string. First it reads in the character \acode. In the string table
that letter has the code $97$, so the code $97$ is outputted. Next,
the character \bcode is read, which has the code $98$. So $98$ is
outputted and then the two strings read so far are appended together
to form the string \abcode. The string table is searched for the
string \abcode, but it cannot be found in the string table, so it is
added to the string table and is assigned the next available code, $256$.

\acode is discarded, \bcode is kept and another \acode is
read. First \bcode is outputted, and the appended string
\bacode is formed. This string doesn't either exist in the table,
 so it is added to table and is given the code $257$.

 Discard \bcode, output \acode and read in another \bcode. The
 resulting appended string is this time \abcode. But wait a minute,
 isn't already that string in the string table? Yes it is, so instead
 of re-adding that string to table, it is kept for the next step in
 the algorithm.

The code for \abcode is outputted, which is $256$, and the character \ccode is
read. The string \abccode doesn't exist in the table, so it is
added to the string table and given the code $258$.

And the algorithm just keeps going on like this. Table
\ref{tab:str-tab-str} shows all the codes that were added during the
compression of the sample string. Table \ref{tab:lzw-walkthru} gives a
detailed walkthrough of the compression of the same string. Do study
both of these tables table carefully and don't continue reading until you
fully understand what happened during the compression of the
string.

\begin{table}
  \centering
  \begin{tabular}{ll}
    \toprule
    String & Code \\
    \midrule
    \strrow{97}{a}
    \strrow{98}{b}
    \strrow{99}{c}
    \dotsrow
    \strrow{256}{ab}
    \strrow{257}{ba}
    \strrow{258}{abc}
    \strrow{259}{cb}
    \strrow{260}{bab}
    \strrow{261}{baba}
    \strrow{262}{aa}
    \strrow{263}{aaa}
    \strrow{264}{aaaa}
    \bottomrule
  \end{tabular}
  \caption{The string table after the LZW algorithm has been run on
    the string \texttt{ababcbababaaaaaaa}.}
  \label{tab:str-tab-str}
\end{table}

\begin{table}
  \centering
  \newcommand{\lzwrow}[4]{#1 & #2 & #3 & #4 \\}
  \begin{tabular}{llll}
    \toprule
    String Code & New Code & Output Code & New table entry \\
    \midrule

    \lzwrow{a}{b}{a = 97}{ab = 256}
    \lzwrow{b}{a}{b = 98}{ba = 257}
    \lzwrow{a}{b}{}{}
    \lzwrow{ab}{c}{ab = 256}{abc = 258}
    \lzwrow{c}{b}{c = 99}{cb = 259}
    \lzwrow{b}{a}{}{}
    \lzwrow{ba}{b}{ba = 257}{bab = 260}
    \lzwrow{b}{a}{}{}
    \lzwrow{ba}{b}{}{}
    \lzwrow{bab}{a}{bab = 260}{baba = 260}
    \lzwrow{a}{a}{a = 97}{aa = 261}
    \lzwrow{a}{a}{}{}
    \lzwrow{aa}{a}{aa = 262}{aaa = 262}
    \lzwrow{a}{a}{}{}
    \lzwrow{aa}{a}{}{}
    \lzwrow{aaa}{a}{aaa = 263}{aaaa = 263}

    \bottomrule
  \end{tabular}
  \caption{Detailed LZW compression on the string \texttt{ababcbababaaaaaaa}.}
  \label{tab:lzw-walkthru}
\end{table}

\section{Technical Implementation the Algorithm}
\label{sec:lzw-enc-algorithm}

In algorithm \ref{alg:lzw-compression} the complete LZW compression
algorithm is presented. Try reading through it at least once,
but I doubt you'd be able to understand all of it at this point. The
implementation of the algorithm turns out not to be as easy as it
sounds.

\begin{algorithm}[H]
  \caption{The LZW compression algorithm.}
  \label{alg:lzw-compression}
  \begin{algorithmic}[1]

    \State \VoidCall{FillInitialStringTable}
    \Let{$nextCode$}{$256$}
    \Let{$stringCode$}{\VoidCall{$ReadByte$}}
    \Let{$charCode$}{\VoidCall{$ReadByte$}}

    \While{\neof}

      \If{\Call{InStringTable}{$stringCode,charCode$}} \label{algl:hasingcheckintable}
        \Let{$stringCode$}{\Call{GetCode}{$stringCode,charCode$}} \label{algl:hasgetcode}
      \Else
        \State \Call{outputCode}{$stringCode$}

        \If{$nextCode \leq maxCode$}

          \State \Call{AddToStringTable}{$nextCode, stringCode, charCode$}\label{algl:hashadd}
          \Inc{nextCode}{1}

        \EndIf

        \Let{$stringCode$}{$charCode$}

      \EndIf

      \Let{$charCode$}{\VoidCall{$ReadByte$}}

    \EndWhile

    \State \Call{outputCode}{$stringCode$}
    \State \Call{outputCode}{$maxValue$}
    \State \Call{outputCode}{$0$} \Comment{Cause the last packet to be
      written } \label{algl:flush}
  \end{algorithmic}
\end{algorithm}

\subsection{Codes sizes}

All a LZW compressed file will consist of after this algorithm has
been run, is just a long sequence of outputted codes.

Since all the of the actual strings(whose length is greater than one)
in the string table have codes values over $255$, bytes will obviously
not be sufficient to store these codes. The code sizes\index{code
  size} used in the LZW algorithm are typically in the ranges $9 \leq
codeSize \leq 15$. But in our examples we will be using 12-bit codes,
as they are most commonly used.

\subsection{String Storage Model}

\newcommand{\strpair}[2]{(#1,#2)}

You could of course just store all the strings in the string table as
real strings. However, these strings are going to end up
taking way more space than they really need to.

As you probably remember from section \ref{sec:lzw-comp-desc}, the string
to be added to the table is just the concatenation of the character
just read and the former string. The concatenation of the characters
characters \texttt{a} and \texttt{b} could be expressed as the string
\texttt{ab}. But however, they could also be described by the
pair\index{pair} \strpair{97}{98}, which consists of the two codes of
the two strings. Okay, there is no real big difference in size yet,
but now consider \texttt{abcbde} and \texttt{a} and their
concatenation \texttt{abcbdea}. If \texttt{abcbde} has the code, say,
289, then obviously the pair \strpair{289}{97} is much more space
efficent than \texttt{abcbdea}.

You may think we are just nitpicking here, but also need to consider
that with huge files this string table could end up becoming huge. And
besides, pair of numbers are often much easier to deal with than
strings, especially in languages like \C!

Using this new string storage model table \ref{tab:str-tab-str}, is
translated to table \ref{tab:str-tab-pair}. Notice that the string
codes of the single character strings whose codes values are less than
$256$ are given the value $-1$  in order to differentiate them from
ordinary strings. You will why need to this when we discuss the
decompression algorithm.

\newcommand{\pairrow}[3]{$#1$ & \strpair{#2}{#3} \\}

\begin{table}
  \centering
  \begin{tabular}{ll}
    \toprule
    String & Code \\
    \midrule
    \pairrow{97}{-1}{a}
    \pairrow{98}{-1}{b}
    \pairrow{99}{-1}{c}
    \dotsrow
    \pairrow{256}{97}{b}
    \pairrow{257}{98}{a}
    \pairrow{258}{256}{c}
    \pairrow{259}{99}{b}
    \pairrow{260}{257}{b}
    \pairrow{261}{260}{a}
    \pairrow{262}{87}{a}
    \pairrow{263}{262}{a}
    \pairrow{264}{263}{a}
    \bottomrule
  \end{tabular}
  \caption{The string table after the LZW algorithm has been run.}
  \label{tab:str-tab-pair}
\end{table}

\subsection{Table size}

Since we are using fixed code sizes there is a limit on how large the
string table can grow. For example, for 12-bit codes the maximum size
of the string table will be $2^{11}=4096$. In algorithm
\ref{alg:lzw-compression} the constants $maxCode$ and $maxValue$ are
used to be make sure that the table doesn't grow beyond it's maximum
size. In algorithm \ref{alg:lzw-constants} we show how set the size
constants for the example code size 12. Notice that the maximum value
of the final code, $maxCode$ is one less than the actual max size of
the table. That's because at the end of algorithm we output the final
code to always be the maximum value of the current code size. You will
soon see why we do this when discuss the decompression algorithm, but for
now ignore it.

\begin{algorithm}[H]
  \caption{Settings the constants for the LZW algorithm for the
    example code size 12.}
  \label{alg:lzw-constants}
  \begin{algorithmic}[1]
    \Let{$codeSize$}{12}
    \Let{$maxValue$}{$(1 << codeSize) - 1$}
    \Let{$maxCode$}{$maxValue - 1$}
  \end{algorithmic}
\end{algorithm}

\subsection{Managing The String Table}

Please Inspect line
\algref{alg:lzw-compression}{algl:hasingcheckintable} and line
\algref{alg:lzw-compression}{algl:hasgetcode} of the compression
algorithm. Since we are clearly using the strings themselves to search
for their corresponding codes, we need to figure out how to find their
respective codes.

One way to implement this would be by using the code as an index to an
array of strings. But this clearly prohibitively slow as you would
have search the entire string table, string by string, when you would
want the code of a specific string.

The easiest way to solve this problem is to just use a hash table. The
string can used to create a key to index the table to get the searched
codes.

Since most modern languages already implement some sort of hash table
in their standard library, this functionality should not be very hard
to implement. If you are using more lower level language like \C, you
will either have to roll your own or use a library. In the sample \C
source code of this chapter a simple hand-rolled hash table
is used to manage the string table.

\subsection{Outputting variable sized codes}

A last thing we'll have to consider is how to actually output the
codes. The file I/O functions of most programming languages do not
support outputting numbers whose sizes are not multiples of 8, so
we'll have to devise a routine of our own for doing this.

Let us consider how to output the codes $5$, $5$, $11$ and $12$. The
binary equivalents of these numbers are 0101, 0101, 1011 and
1100. Since the maximum number of bits needed to store these numbers
is $4$ we'll be outputting codes of size 4.

Now, the thing that the want to do with these bytes is this: we want
to \textit{pack} these variably sized codes into
\textit{packets}\index{packets} of 8-bits integers, or bytes as we
usually call them.

\subsubsection{Packing order}

But we first need to make a decision: when, for example, the codes
1011 and after 1100 are to be packed in order, there can actually be two
different resulting byte packets: 10111100 or 11001011. In the first
case the bits of the codes start to get packed at the \textit{most
  significant bits} of the resulting packet.  The most significant
bits are the bits whose values are the greatest when toggled. In the
second case the bits from the codes start to get written at the
\textit{least significant bits}.

The first of these packing order we'll from now on call
MSBF\index{MSBF} which stands for \textbf{M}ost \textbf{S}ignificant
\textbf{B}its \textbf{F}irst. And the second order we'll refer to as
LSBF\index{MSBF}, which of course stands for \textbf{L}east
\textbf{S}ignificant \textbf{B}its \textbf{F}irst

\subsubsection{The Algorithm}

\paragraph{Smaller Codes}

The packing order we'll be using in the algorithm we'll be describing is LSBF,
because that is the packing order used in the LZW compression of GIF
files \cite{gif89a}.

So remember, the codes that wanted to write was 0101, 0101, 1011 and
1100. We'll first request an empty byte packet and make it empty:
0000 0000. Now we'll set the bits of the first four least
significant bits of the packet to the bits of the first code:
0101. This can trivially be done using the bitwise-OR operation:

\begin{center}
  \begin{tabular}{lr}
    & 0000 0000  \\
    $\BitOr$ & 0101 \\
    \hline
    & 0000 0101 \\
  \end{tabular}
\end{center}

After this operation, only half of the byte packet has been filled, so
we won't write packet quite yet. We'll put the writing operation on
hold until we've read the next code.

The next code 0101 has now arrived. We now set the four most
significant bits of the current package to the bits of this packet. So
we'll have to use a bitwise OR operation. But we cannot do this in the
same fashion that we wrote the last packet. We first have to left
bitwise shift the bits of the current code, to make sure that we only
write to the four most significant bits of the current packet. The
number of bits remaining to be set in the current package is $4$. And
that is how many bits we'll bitwise left shift the current code value:
$4 \ShiftLeft 0101 = 0101\ 0000$. And after this the bitwise OR
operation is finally performed:

\begin{center}
  \begin{tabular}{lr}
    & 0000 0101  \\
    $\BitOr$ & 0101 0000 \\
    \hline
    & 0101 0101 \\
  \end{tabular}
\end{center}

Now we have filled the entire packet; the packet is thus outputted and
we request a new empty packet. We'll fill this packet with the two
remaining codes 1011 and 1100 in the same way we filled the last
packet, and we end up making the packet  1100 1011.

\paragraph{Larger Codes}

But this sort of reasoning doesn't work for codes of sizes greater
than $8$. If the codes have sizes that are greater than $8$, the codes
will always contain enough data to fill a byte packet, but we'll also
have to save small unused chunks of the codes that are to be used for
the next packet.

Let's say we want to output the two codes 0110 1101 0111 and 0010 1100
0100 and let's also say that these codes both have the code size
$12$.

Our first code is $0110\ 1101\ 0111$. We'll start by filling the packet
with the 8 least significant bits of this code. The packet then has
the value 1101 0111. And already the packet is filled. So it is
outputted and new empty packet is requested. But we cannot yet throw
away the code we are processing; we haven't yet dealt with 4
most-significant bits of it! So what we'll do is that we'll bitwise
right shift the code 8 times: $0110\ 1101\ 0111 \ShiftRight 8 =
0110$. The number $8$ is used because that is the number of bits that
fit in a full packet. Good, now these four bits are then set to be the
4 least significant bits of the new packet. And so after dealing with
the first code we have outputted a packet with the value 1101 0111 and
the value of the new packet is 0000 0000 0110.

In the  same manner, the  next code $0010\  1100\ 0100$ is  handled: the
four most significant  bytes of the new packet are  set to $0100$, the
code is  right shifted 4 steps;  because that is the  number bits that
was  remaining to  be added  to the  package at  the beginning  of the
processing of the code; the  newly filled packet is then outputted and
the  next packet is  filled with  the remaining  bits of  the current,
modified, code.

In algorithm \ref{alg:variable-codes-output} the complete variable
sized codes output algorithm is given. In this algorithm we introduce
a new function \Call{FirstNBits}{$n,bits$}\index{FirstNBits}. What
this function does, is that gets the value the first $bits$ least
significant bits of the number $n$. So the call
\Call{FirstNBits}{$001101,3$}, for example, would result in the value
$010$.

\begin{algorithm}[H]
  \caption{Algorithm for outputting variably sized codes.}
  \label{alg:variable-codes-output}
  \begin{algorithmic}[1]
    \Let{$remainingPacketBits$}{8}
    \Let{$packet$}{0}
    \Let{$shift$}{0}
    \Let{$codeSize$}{12}

    \Function{OutputCode}{$code$}

      \Let{$remainingCodeBits$}{$codeSize$}

      \linecomment{While the entire code hasn't yet been processed}
      \While{$remainingCodeBits > 0$}

        \linecomment{If the packet will get filled in this packing.}
        \If{$remainingPacketBits < remainingCodeBits$}

          \linecomment{Read as many bits necessary the fill up the
            packet.}
          \Let{$firstNBits$}{\Call{FirstNBits}{$code,remainingPacketBits$}}
          \Let{$packet$}{$packet \BitOr (firstNBits \ShiftLeft shift)$}

          \linecomment{Write the packet}
          \State \Call{WriteByte}{$packet$}

          \linecomment{Throw away the bits of the code that have been
            read to the packet.}
          \Dec{remainingCodeBits}{remainingPacketBits}
          \Let{$code$}{$code \ShiftRight remainingPacketBits$}

          \linecomment{Reset the packet}
          \Let{$remainingPacketBits$}{$8$}
          \Let{$packet$}{$0$}
          \Let{$shift$}{$0$}

        \Else

        \linecomment{If the rest of the code fit in the entire
          packet.}

          \linecomment{Read in the entire code to the packet.}
          \Let{$code$}{\Call{FirstNBits}{$code,remainingCodeBits$}}
          \Let{$packet$}{$packet \BitOr(
             code \ShiftLeft shift)$}

          \linecomment{Handle the number shifting of the packet.}

          \Inc{shift}{remainingCodeBits}
          \Dec{remainingPacketBits}{remainingCodeBits}

          \linecomment{The entire code has been processed, so terminate the loop}
          \Let{$remainingCodeBits$}{$0$}
        \EndIf
      \EndWhile
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\subsubsection{Flushing The Packets}

Let's say we want to write the two codes $11000$ and $11011$. To do
this we perform two calls to the function explained in algorithm
\ref{alg:variable-codes-output}. However, this only results in the
packet $0111 \ 1000$ being outputted, and the rest of two bits $11$ in
the last packet $11011$ ends up being put on hold for the next
code. But we have already written the two codes we want to output, so
how may we force the last two bits being written?  This turns out to
be very easy to do, as all we have to do is write an empty extra code
$0000 \ 0000$. This results in the last two bits being written out in
the form of the packet $0000 \ 0011$.

And all of this is why line \algref{alg:lzw-compression}{algl:flush}
even exists. Otherwise, the last few bits of the max value would not
get outputted, and this would cause huge problems for the
decompressor.

\section{Description of the Decompression algorithm}

Using the compression algorithm LZW on the string
\texttt{ababcbababaaaaaaa} produces the compressed data stream
\texttt{97 98 256 99 257 260 97 262 263 264 4095}. Since we were using
12-bit codes to encode the data, the maximum value of an unsigned
12-bit number, $2^{12} - 1 = 4095$, is used to terminate it. This is to
make sure that the decompressor knows when to stop reading.

As you may have noticed, in a LZW compressed file the string table is
not included. Then how could you possibly decompress the file without
such essential information? It turns out that all the LZW
decompression algorithm do is basically the same thing that the
compression algorithm does; it just reconstructs the string table as
it goes along and reads and decompresses the file at the same time.

So, we wanted to decompress the data stream \texttt{97 98 256 99 257
  260 97 262 263 264 4095}. The decompressor first makes the same
table \ref{tab:str-tab-ascii}  that the LZW compressing algorithm did at the beginning of
its process.

First the first code is read simply and outputted, which is $98$, or
simply the letter \texttt{a}. And in the same fashion the next code
$98$ is read and outputted as \texttt{b}.

Now \texttt{a} and \texttt{b} are appended together to the string
\texttt{ab}. This string is added to the string table and is given the
code $256$.

A new code is read, this time it's $256$, and \texttt{a} is
discarded. $256$ is now to be translated. We just assigned the code
$256$ the string \texttt{ab}, so the translation of $256$ is obviously
\texttt{ab} and because of that \texttt{ab} is outputted.

Now we need to form the next string to be added the table,
\texttt{ba}. To do this, we take the former string \texttt{b} and add
to the first character of the current string \texttt{ab}, thus forming
the desired string \texttt{ba}. this string is added to the table with
the code $257$. And in this way all of the other strings to be added
to the table.

But we're going to keep doing this for a whole. You will soon see
why. $99$ is read and then is outputted as \texttt{c}. \texttt{ab} and
\texttt{c} are appended together to form the string \texttt{abc} and then
\texttt{abc} is added to the string table with the code $258$.

$257$ is read in. This is the code for \texttt{ba}.Since the former
code was \texttt{c}, the string to be added to the table is
\texttt{cb}, and it is given the code $260$.

But now we read in the code $260$ before we have even added it to the
table! Up to this we have so far uncompressed up to the string
\texttt{ababcba}. What remains is the string \texttt{babaaaaaaa}. The
problen here is that the compressor outputted a code before the
decompressor was able to define it. So we need to handle this as a
special case. We need to figure out how to construct the table entry
bab=260 with the information we currently got. We could actually
pretty easily construct this appending the old code \texttt{ba} to the
first character of the old code \texttt{b}.

\newcommand{\ko}{\ensuremath{k\omega}\xspace}
\newcommand{\kok}{\ensuremath{\ko k}\xspace}
\newcommand{\kokok}{\ensuremath{\kok \omega k}\xspace}

The general problem could described like: If the string \ko is already
in the string table and if the string \kokok is encountered, then
compressor will first add \kok the string table and then output
\ko. After the code for \kok is output before the decompressor is able
to define it. But this table entry can then be constructed using $\ko
+k$.  So this is really only a special case you need to handle when a
code is not defined in the string table.

So the decompressor just keeps working through the data like this while
deconstructing the string table that was used to compress it. It reads
until it encounters the maximum value of the current code size $x$,
$2^{x}-1$; for 12-bit codes this $2^{12} - 1 = 4095$, as can be seen
from out test data stream, \texttt{97 98 256 99 257 260 97 262 263 264
  4095}. The entire decompression process is shown in table \ref{tab:lzw-dec-walkthru}.

\begin{table}
  \centering
  \noindent\makebox[\textwidth]{%
  \begin{tabular}{lllll}
    \toprule
    Old Code & Newcode Code & Input Code & Output Codes & New table entry \\
    \midrule

    97=a & & 97=a & a=97 & \\
    97=a & 98=b & 98=b & b=98 & ab=256 \\
    98=b & 256=ab & 256=ab & a=97,b=98 & ba=257 \\
    ab=256 & c=99 & c=99 & c=99  & abc=258 \\
    c=99 & 257=ba & 257=ba & b=98,a=97 & cb=259 \\
    bab & 260 & 260&b=98,a=97,b=98 &bab=260 \\
    bab=260 & a=97  & a=97 & a=97 & baba=261\\
    bab=260 & a=97 & a=97 & a=97 & baba=261\\

    aa & 262 & 262 & a=97,a=97 & aa=262 \\

    aaa & 263 & 263 & a=97,a=97,a=97 & aaa=263 \\

    aaa=263 & a=97 & a=97 & a=97 & aaaa=264  \\

    a=97 & 4095=maxValue & 4095=maxValue & STOP &  \\

    \bottomrule
  \end{tabular}}
  \caption{Detailed LZW decompression on the string \texttt{ababcbababaaaaaaa}.}
  \label{tab:lzw-dec-walkthru}
\end{table}

\section{Technical Implementation of the Decompression Algorithm}

And the algorithm we have just described can be seen in algorithm
\ref{alg:lzw-working-decompression}. Having discussed the compression
algorithm very much in depth, you should be able to perfectly
understand most of this alglorithm. However, there are still some more
things we need to discuss in the implementation of this algorithm
until we completely are done with discussing the LZW algorithm.

\begin{algorithm}[H]
  \caption{LZW working decompression algorithm.}
  \label{alg:lzw-working-decompression}
  \begin{algorithmic}[1]

    \State \VoidCall{FillInitialStringTable}
    \Let{$nextCode$}{$256$}

    \Let{$oldCode$}{\VoidCall{$InputCode$}}
    \State \Call{writeByte}{$oldCode$}

    \Let{$character$}{$oldCode$}

    \Let{$newCode$}{\VoidCall{$InputCode$}}

    \While{$newCode \neq maxValue$}

      \If{$\NOT$ \Call{IsInTable}{$newCode$}} \Comment{The special case}
        \Let{$string$}{\Call{Translate}{oldCode}}
        \Let{$string$}{$string + character$}
      \Else
        \Let{$string$}{\Call{Translate}{$newCode$}}
      \EndIf

      \State \Call{outputString}{$string$}

      \Let{$character$}{$string[0]$} \Comment{Get the first character
        of the translated string.}

      \If{$nextCode \leq maxCode$}
        \State \Call{$AddToStringTable$}{$nextCode,oldCode, character$}

        \Inc{nextCode}{1}
      \EndIf

      \Let{$oldCode$}{$newCode$}

      \Let{$newCode$}{\VoidCall{$ReadByte$}}

    \EndWhile
  \end{algorithmic}
\end{algorithm}

\subsection{Translating string codes}

First we need to figure out how translate string from the code pair format as we
discussed in section \ref{sec:lzw-enc-algorithm}.

Please see algorithm \ref{alg:translate-string-code}. This puts the
decoded string of the code $code$ \textit{reversed} into the string
$decodedString$. The string ends up being reversed because we
basically are translating the code from the end of the string to the
beginning. As you can see, we are just working through character code
after character code looking up the next code in the table using the
string code. For this algorithm, we have chosen to put a negative one
into the stringCode of pairs that represent single characters. If we
have reached such a pair, we have reached to beginning of the string
and we are done translating it.

This discussion leads up to another point. \textit{The decompressor
  has no need of a hash table to manage the string table}. This makes sense as
we are really only using the number codes to look up strings in the
table to manage the string table. Since the codes are numbers, they
can be used as indices and hence there is no need for a hash table,
which makes the work for the compressor one heck of a lot easier.

\begin{algorithm}[H]
  \caption{Translating a string code to normal string. Where code is
    the code we want to translate. }
  \label{alg:translate-string-code}
  \begin{algorithmic}[1]
    \Let{$\strpair{stringCode}{characterCode}$}{$stringTable[code]$}
    \While{\True}
      \Let{$decodedString$}{$decodedString + characterCode$}
      \If{$stringCode = -1$}
        \Break
      \Else
        \Let{$\strpair{stringCode}{characterCode}$}{$stringTable[stringCode]$}
      \EndIf
    \EndWhile
  \end{algorithmic}
\end{algorithm}

\subsection{Inputting Variably Sized Codes}

We also need to construct an algorithm for inputting the variably
sized codes output by the compression algorithm. This algorithm is
algorithm \ref{alg:variable-codes-input}. Because the way this algorithm operates is extremely
similar to the outputting algorithm, I will not offer an in depth
discussion of it. Just read and study the comments carefully and you
should be fine.

\begin{algorithm}[H]
  \caption{Algorithm for inputting variably sized codes.}
  \label{alg:variable-codes-input}
  \begin{algorithmic}[1]
    \Let{$remainingPacketBits$}{8}
    \Let{$packet$}{\VoidCall{ReadByte}}

    \Function{OutputCode}{$codeSize$}

      \Let{$remainingCodeBits$}{$codeSize$}
      \Let{$code$}{$0$}
      \Let{$shift$}{$0$}

      \linecomment{While an entire code hasn't yet been read.}
      \While{$remainingCodeBits > 0$}

        \linecomment{If the current packet doesn't contain enough bits
          to fill the current code.}
        \If{$remainingPacketBits < remainingCodeBits$}

          \linecomment{Read the remaining bits of the packet.}
          \Let{$firstNBits$}{\Call{FirstNBits}{$packet,remainingPacketBits$}}
          \Let{$code$}{$code \BitOr (firstNBits \ShiftLeft shift)$}

          \linecomment{Read in a new packet. }
          \Let{$packet$}{\VoidCall{ReadByte}}

          \linecomment{Handle the left shifting of bits.}
          \Inc{shift}{remainingPacketBits}
          \Dec{remainingCodeBits}{remainingPacketBits}

        \Else

        \linecomment{If there are enough bits in the current packet to
          fill the entire code.}

          \linecomment{Read in the entire code to the packet.}
          \Let{$highestCodeBits$}{\Call{FirstNBits}{$packet,remainingCodeBits$}}
          \Let{$code$}{$code \BitOr(highestCodeBits \ShiftLeft shift)$}

          \linecomment{Discard the bits from the packet that were
            written to the code.}

          \Let{$packet$}{$packet \ShiftRight remainingCodeBits$}
          \Dec{remainingPacketBits}{remainingCodeBits}

          \linecomment{The entire code has been processed, so terminate the loop}
          \Let{$remainingCodeBits$}{$0$}
        \EndIf
      \EndWhile
    \EndFunction
  \end{algorithmic}
\end{algorithm}


\section{Efficiency}

In this section we will be testing how good of a compression ratio the
LZW algorithm have on different sorts of files and data with
different codes sizes.

We will not however be discussing about the \textit{performance} of
the algorithm. Read a more advanced book on data compression of you
want such information.

\subsection{The Canterbury Corpus}

As you may noticed, doing LZW compression on small data is a very small
gain operation. However, doing this on larger files do actually yield a
significant decrease in file sizes.

In the chapter, we introduce a set of test files we'll be using the
demonstrate the efficiency of compression algorithms. A corpus of
files for designed testing new compression algorithms called the
Canterbury Corpus is that we will be using. These files we're selected
out of thousands of other files because they demonstrate the
efficiency of compression algorithms the best \cite{arnold:corpus}.

Table \ref{tab:corp-files} summaries all the files we'll be using. They can all be
downloaded from \cite{powell:desc-corp}.

\todo{typesett the file names using typewriter font.}
\begin{table}
  \centering
  \begin{tabular}{ll}
    \toprule
    File & Category \\
    \midrule
    alice29.txt & English text \\
    asyoulik.txt & Shakespeare \\
    cp.html & HTML source \\
    fields.c & C source \\
    grammar.lsp & LISP source \\
    kennedy.xls & Excel Spreadsheet \\
    lcet10.txt & Technical writing \\
    plrabn12.txt & Poetry \\
    sum & SPARC Executable \\
    xargs.1 & GNU manual page \\
    E.coli & Complete genome of the E. Coli bacterium \\
    bible.txt & The King James version of the bible \\
    world192.txt & The CIA world fact book \\
    \bottomrule
  \end{tabular}
  \caption{}
  \label{tab:corp-files}
\end{table}

\subsection{The Test}

The test we will be doing in this section as that we will be testing
how the compression ratio vary with different code sizes and different
kinds of files. We'll running the test on all the files in table and
we'll doing it for every file with the code sizes in the range $9 \leq
codeSize \leq 15$

\subsection{The Test Results}

In table \ref{tab:lzw-test-results} we show the results of the test.

\begin{table}
  \scriptsize
  \centering
  \input{../code/lzw/table.tex}
  \caption{LZW test results. The different percentages the represent the respective compression <ratios of that code size.}
  \label{tab:lzw-test-results}
\end{table}

\subsection{Discussion}

And now we are to discuses these test results, and see if they make us
realist some new things about the LZW algorithm.

The first thing we notice is that more is not always better. And by
that I am referring to the code sizes. Bigger code sizes does
\textit{not} always result in better compression. But what we should
also realise is the fact that codes with bigger sizes also take up
more space, than smaller codes. See for example the files
\verb|fields.c| and \verb|grammar.lsp|, these are source and/or text
files. What is peculiar about these files is that for highest code
size, $15$, they do not achieve the highest compression. What is even
stranger is that these files are program source code, meaning that are
highly likely chok of redundancies.

But we should also realize that these are not very large, they are
some of the smallest files. So it highly likely that is because the
15-bit codes are not really used. 15-bit codes means that the string
table has a maximum size of $2^{15} = 32768$, which is nowhere near
the sizes of these files. And thus, the conclusion we reach is that
these files were compressed poorly using 15-bit codes because the
extra bit added to 14-bit codes was not even used. The files were just
to small to even use and the compression of the file was over before
the string table was even full.

And true enough, if we inspect the larger files, say \verb|bible.txt|
or \verb|world192.txt|, we see that larger code sizes do indeed mean
greater compression. But this only because these files were large
enough to actually make use of the extra bits the larger code sizes
added.

\FloatBarrier

\printbibliography[heading=subbibliography]

\end{refsection}

