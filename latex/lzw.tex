\begin{comment}
  \bibliography{project.bib}
\end{comment}

\chapter{LZW}
\label{ch:rle}

\begin{refsection}

In this chapter we will discuss the data compression algorithm \lzw\index{LZW} as
it is described in
\cite{nelson89:_lzw_data_compr,Welch:1984:THD:1319729.1320134,Salomon:2004:DCC}.

\section{A (very) short history}

\lzw stands for \textbf{L}empel, \textbf{Z}iv and
\textbf{W}elch. Abraham Lempel and Jacob Ziv are two researches who
developed the two compression methods \textsc{LZ77} and
\textsc{LZ78}. These two compression algorithms becamse the first two
dictionary based compression methods and they became very popular and
sparked an entire family of \textsc{LZ} methods, and \lzw is in that family.
\cite{Salomon:2004:DCC}.

\section{Compression algorithm}

\subsection{Description}
\label{sec:lzw-desc}

The \lzw compression\index{\lzw compression} algorithm is best
understood by walking through the LZW algorithm's process of
compressing some sample data.

Let's we want to compress the string \texttt{ababcbababaaaaaaa}. The
algorithm start by filling a string table\index{string table} until it
contains all of the one length symbols in the default character set
that fit in a byte, from 0 to 255. For this example we will use the
character set \ascii \cite{rfc20}. Table shows how this table ends up looking like
when it is filled \ref{tab:str-tab-ascii}. As can be seen, every entry
in the table consists of a pair a string it's corresponding number
value,We will from now on refer to these numbers as codes\index{code}.

\newcommand{\dotsrow}{\dots & \dots \\}
\newcommand{\strrow}[2]{$#1$ & #2 \\}

\begin{table}
  \centering
  \begin{tabular}{ll}
    \toprule
    String & Code \\
    \midrule

    \dotsrow
    \strrow{33}{!}
    \strrow{34}{"}
    \strrow{35}{\#}
    \dotsrow
    \strrow{97}{a}
    \strrow{98}{b}
    \strrow{99}{c}
    \strrow{100}{d}
    \strrow{101}{e}
    \dotsrow
    \strrow{255}{}

    \bottomrule
  \end{tabular}
  \caption{The initial LZW string table filled with all the \ascii
    characters.}
  \label{tab:str-tab-ascii}
\end{table}

Now the algorithm start going through the sample string. First it
reads the first character \texttt{a}. In the string table that letter
has the code$97$, so we just output this code value. Next, the
character \texttt{b} is read, which has the code $98$. The code of b,
$98$, is outputted and then the two strings read so far are
appended together to form the string \texttt{ab}. The string table is
searched for the string \texttt{ab}, but it cannot be found in the
string table, so it is \textit{added} to the string table is assigned
the next available code, $256$.

\texttt{a} is discarded, \texttt{b} is kept and another \texttt{a} is
read. First \texttt{b} is outputted, and this time the algortihm ends
with the appended string \texttt{ba}. This string doesn't either exist
in the table and so it is added the table and assigned the code $257$.

Discard \texttt{b}, output \texttt{a} and read in another
\texttt{b}. Now something very interesting thing happens; The
resulting appended string this time is \texttt{ab}. But wait a minute,
isn't already that string to the string table? Yes, it is, so instead
of re-adding that string to table, it is kept for the next step in the
algorithm.

The code for \texttt{ab} is outputted and the character \texttt{c} is
read. The string \texttt{abc} doesn't exist in the table, so it is
added to the string table and given the code $258$. And the algorithm
just keeps going on like this. Table \ref{tab:str-tab-str} shows the
codes that were added during the compression of the string. Table
\ref{tab:lzw-walkthru} gives a detailed walkthrough of the compression
of the string, do study this table carefully and don't go on reading
until you fully understand it.

\begin{table}
  \centering
  \begin{tabular}{ll}
    \toprule
    String & Code \\
    \midrule

    \dotsrow
    \strrow{256}{ab}
    \strrow{257}{ba}
    \strrow{258}{abc}
    \strrow{259}{cb}
    \strrow{260}{bab}
    \strrow{261}{baba}
    \strrow{262}{aa}
    \strrow{263}{aaa}
    \strrow{264}{aaaa}
    \bottomrule
  \end{tabular}
  \caption{The string table after the \lzw algorithm has been run.}
  \label{tab:str-tab-str}
\end{table}

\begin{table}
  \centering
  \newcommand{\lzwrow}[4]{#1 & #2 & #3 & #4 \\}
  \begin{tabular}{llll}
    \toprule
    String Code & New Code & Output Code & New table entry \\
    \midrule

    \lzwrow{a}{b}{a = 97}{ab = 256}
    \lzwrow{b}{a}{b = 98}{ba = 257}
    \lzwrow{a}{b}{}{}
    \lzwrow{ab}{c}{ab = 256}{abc = 258}
    \lzwrow{c}{b}{c = 99}{cb = 259}
    \lzwrow{b}{a}{}{}
    \lzwrow{ba}{b}{ba = 257}{bab = 260}
    \lzwrow{b}{a}{}{}
    \lzwrow{ba}{b}{}{}
    \lzwrow{bab}{a}{bab = 260}{baba = 260}
    \lzwrow{a}{a}{a = 97}{aa = 261}
    \lzwrow{a}{a}{}{}
    \lzwrow{aa}{a}{aa = 262}{aaa = 262}
    \lzwrow{a}{a}{}{}
    \lzwrow{aa}{a}{}{}
    \lzwrow{aaa}{a}{aaa = 263}{aaaa = 263}

    \bottomrule
  \end{tabular}
  \caption{LZW control flow.}
  \label{tab:lzw-walkthru}
\end{table}

\subsection{Algorithm}

In algorithm \ref{alg:lzw-compression} the complete LZW compression
algorithm is presented. Try reading through it at least once,
but I doubt you'd be able to understand all of it at this point. The
implementation of the algorithm turns out not to be as easy as it
sounds.

\begin{algorithm}[H]
  \caption{The LZW compression algorithm.}
  \label{alg:lzw-compression}
  \begin{algorithmic}[1]
    \Let{$nextCode$}{$256$}
    \Let{$stringCode$}{\VoidCall{$ReadByte$}}
    \Let{$charCode$}{\VoidCall{$ReadByte$}}

    \While{\neof}

      \If{\Call{InStringTable}{$stringCode,charCode$}} \label{algl:hasingcheckintable}
        \Let{$stringCode$}{\Call{GetCode}{$stringCode,charCode$}} \label{algl:hasgetcode}
      \Else
        \State \Call{outputCode}{$stringCode$}

        \If{$nextCode \leq maxCode$}

          \State \Call{AddToStringTable}{$nextCode, stringCode, charCode$}\label{algl:hashadd}
          \Let{$nextCode$}{$nextCode + 1$}

        \EndIf

        \Let{$stringCode$}{$charCode$}

      \EndIf

      \Let{$charCode$}{\VoidCall{$ReadByte$}}

    \EndWhile

    \State \Call{outputCode}{$stringCode$}
    \State \Call{outputCode}{$maxValue$}

  \end{algorithmic}
\end{algorithm}

\subsubsection{Codes sizes}

All a \lzw compressed file will consist of after this algorithm has
been run, is just a long sequence of outputted codes.

Since all the of the actual strings in the string table have codes
values over $255$, bytes will obviously not be sufficient to store
these codes. The code sizes\index{code size} used in the \lzw
algorithm are typically in the ranges $9 \leq codeSize \leq 15$. But
among all the different code sizes 12-bit codes are probably the most
frequent ones, which will be the code size we will use in our examples from
now on.

File I/O Functions for writing data to files are not typically
designed to write numbers whose bit-count are not multiples of 8, so
we will need to construct a function, an algorithm, for doing this. It
should at least support writing numbers in the ranges  $9 \leq x \leq 15$.

\todo{discuss the function outputCode here?}

\subsubsection{String Storage Model}

\newcommand{\strpair}[2]{(#1,#2)}

You could of course just store all the strings in the string table as
real strings. However, these strings are going to end up
taking way more space than they really need to.

As you probably remember from section \ref{sec:lzw-desc}, the string
to be added to the table is just the concatenation of the character
just read and the former string. The concatenation of the characters
characters \texttt{a} and \texttt{b} could be expressed as the string
\texttt{ab}. But however, they could also be described by the
pair\index{pair} \strpair{97}{98}, which consists of the two codes of
the two characters. Okay, there is no real big difference in size yet,
but now consider \texttt{abcbde} and \texttt{a} and their
concatenation \texttt{abcbdea}. If \texttt{abcbde} has the code, say,
289, then surely the pair \strpair{289}{97} is much more space
efficent than \texttt{abcbdea}?  Yes, it is of course!

You may think we are just nitpicking here, but also need to consider
that with huge files this string table could end up becoming very big
and long. And besides, pair of numbers are often much easier to deal
with than strings, espically in languages like \C! So there's end much
smaller chance of making sily mistakes and creating bugs that could
have been avoided if you hade selected your string storage model more
wisely.

Using this new string storage model table \ref{tab:str-tab-str}, is
translated to table \ref{tab:str-tab-pair}. You also may notice that we end
creating this beautiful recursive structure using this model. We will
find out more about this later when are going to decompress the data.

\newcommand{\pairrow}[3]{$#1$ & \strpair{#2}{#3} \\}

\begin{table}
  \centering
  \begin{tabular}{ll}
    \toprule
    String & Code \\
    \midrule
    \dotsrow
    \pairrow{256}{97}{b}
    \pairrow{257}{98}{a}
    \pairrow{258}{256}{c}
    \pairrow{259}{99}{b}
    \pairrow{260}{257}{b}
    \pairrow{261}{260}{a}
    \pairrow{262}{87}{a}
    \pairrow{263}{262}{a}
    \pairrow{264}{263}{a}
    \bottomrule
  \end{tabular}
  \caption{The string table after the \lzw algorithm has been run.}
  \label{tab:str-tab-pair}
\end{table}

\subsubsection{Table size}

Since we are using fixed code sizes there is a limit on how large the
string table can grow. For example, for 12-bit codes the maximum size
of the string table will be $2^{11}=4096$. In algorithm
\ref{alg:lzw-constants} we show how set the size constants for the
example code size 12. Notice that the maximum value of the final code,
$maxCode$ is one less than the actual max size of the table. That's
because at the end of algorithm \ref{alg:lzw-compression} we output
the final code to always be the maximum value of the current code size
type. You will see why we do this when discuss the decompression
algorithm, but for now ignore it.

\begin{algorithm}[H]
  \caption{Settings the constants for the LZW algorithm for the
    example code size 12.}
  \label{alg:lzw-constants}
  \begin{algorithmic}[1]
    \Let{$codeSize$}{12}
    \Let{$maxValue$}{$(1 << codeSize) - 1$}
    \Let{$maxCode$}{$maxValue - 1$}
  \end{algorithmic}
\end{algorithm}

\subsubsection{Managing The String Table}

Please Inspect line
\algref{alg:lzw-compression}{algl:hasingcheckintable} and line
\algref{alg:lzw-compression}{algl:hasgetcode}. Since we are clearly
using the strings themselves to search for their corresponding codes,
we need to figure out how to find them \todo{fix this paragraph plz}. One way to implement these
two functions would be two use the code as an index to an array of
strings. But this clearly prohibitively slow as you would have
search the entire string table, string by string, when you would want
the code of a string.

The easiest way to solve this problem is to just use a hash table. The
string can used to create a key to index the table to get the needed
codes.

Since most modern languages already include some sort of hash table in
their standard library, this should not be very hard to implement. If you
are using more lower level language like \C, you will either have
to roll your own or use a library. In the sample \C source code of
this a simple chapter a simple hand-rolled hash table is used to
manage the string table.

\section{Decompression algorithm}

\subsection{Description}

Using the compression algorithm LZW we on the string
\texttt{ababcbababaaaaaaa} we end up with the compressed data stream
\texttt{97 98 256 99 257 260 97 262 263 264 4095}. We were using
12-bit codes to encode the data, and so the maximum value of an
unsigned 12-bit number is used to terminate it. This is to make sure
that the decompressor knows when to stop reading the data.

As you may have noticed, in a LZW compressed file the string table is
not included. Then how could you possibly decompress the file without
such essential information? It turns out that all the corresponding
LZW decompression algorithm do is basically the same as the
compression aglorithm do; it just constructs the string table as it
goes read and compresses the file at the same time.

It is actually very simple; So, we wanted to decompress the string
\texttt{97 98 256 99 257 260 97 262 263 264 4095}. The decompressor
first reads the first code, $97$, which is just the letter a and the
letter a is outputted. Then the next code is read in, $98$, or simply
b. The first characater is the second string is b. And so the former
character a and the first string of the current string are appended
together and then added to the table, creating the very first table
entry, \strpair{97}{98} and it is assigned the code $256$. A new code,
256 is read and the old \texttt{a} is discarded. $256$ is now to be
translated. We just assigned the code $256$ the string \texttt{ab}, so
the translation of $256$ is obvious \texttt{ab}. The first character
of the string \texttt{ab} is \texttt{a} and thus the old string b and
the first characer of the new string \texttt{a} are added
together. And so ths second string table entry was constructed, and
given the value $257$.

The decompressor jsut keeps working through the data like this while
deconstructing the string table that was used to compress it. It reads
until it encounters the maximum value of the current code size $x$,
$2^{x}-1$; for 12-bit codes this $2^{12} - 1 = 4095$, as can be seen
from out test data stream, \texttt{97 98 256 99 257 260 97 262 263 264
  4095}.

\subsection{Almost working Algorithm}

And the algorithm we just described can be seen in algorithm
\ref{alg:lzw-non-working-decompression}. Having discussed the
compression algorithm very much in depth, you should be able to
perfectly understand must of this alglorithm. However, there is still
some more things we need to discuss until we are done with the \lzw
algorithm. Do notice that I say that algorithm is non-working. I still
present  to you the non-working algorithm because it works a majority
of the time and it is much easier to explain. In the next section, we
will present the working LZW decompression algorithm.

\begin{algorithm}[H]
  \caption{LZW non-working decompression algorithm.}
  \label{alg:lzw-non-working-decompression}
  \begin{algorithmic}[1]
    \Let{$oldCode$}{\VoidCall{$InputCode$}}
    \State \Call{WriteByte}{$oldCode$}

    \Let{$newCode$}{\VoidCall{$ReadByte$}}
    \While{$newCode \neq maxValue$}

      \Let{$string$}{\Call{translate}{$newCode$}}
      \State \Call{outputString}{$string$}
      \Let{$character$}{$string[0]$} \Comment{Get the first character
        of the translated string.}

      \State \Call{$AddToStringTable$}{$oldCode, character$}

      \Let{$oldCode$}{$newCode$}

      \Let{$newCode$}{\VoidCall{$ReadByte$}}
    \EndWhile
  \end{algorithmic}
\end{algorithm}

\subsubsection{Translating string codes}

Figuring out how to translate string codes of the code pair format as we
previously discussed. See algorithm
\ref{alg:translate-string-code}. This puts the decoded string of the
code $code$ \textit{reversed} into the string $decodedString$. The
stirng ends up being reversed because we are tranlating the code from
the end of the string to the beginning. As you can see, we are just
working thourgh character code after character code looking up the
next code in the table using the string code. For this algorithm, we
have chosen to put negative one into pairs that represent single
characters. If we have reached such a pair, we have reached to
beginning of the string and we are done translating it.

This discussing leads up to another point. \textit{The decompressor
  has no need of a hash table to store the codes}. This makes sense as
we are really only using the number codes to look up strings in the
table to manage the string table. Since the codes are numbers, they
can be used as indices and hence there is no need for a hash table.

\todo{fix string format}
\begin{algorithm}[H]
  \caption{Translating a string code to normal string.}
  \label{alg:translate-string-code}
  \begin{algorithmic}[1]
    \Let{$\strpair{stringCode}{characterCode}$}{$code$}
    \Let{$decodedString$}{$""$}
    \While{\True}
      \Let{$decodedString$}{$decodedString + characterCode$}

      \If{$stringCode = -1$}
        \Break
      \Else
        \Let{$\strpair{stringCode}{characterCode}$}{$stringCode$}
      \EndIf
    \EndWhile
  \end{algorithmic}
\end{algorithm}

\subsection{Working algorithm}

Now we are to discuss the fully working LZW compression
algortithm. This algortihm is not really much different from the
non-working one. Because it is only of a very,very rare edge the the
last algorithm may fail to work. And now, without any further ado, the
fully working LZW compresson algorithm is presented at algortihm
\ref{alg:lzw-working-decompression}.

\begin{algorithm}[H]
  \caption{LZW non-working decompression algorithm.}
  \label{alg:lzw-working-decompression}
  \begin{algorithmic}[1]
    \Let{$oldCode$}{\VoidCall{$InputCode$}}
    \State \Call{WriteByte}{$oldCode$}
    \Let{$character$}{\VoidCall{$oldCode$}}

    \Let{$newCode$}{\VoidCall{$ReadByte$}}

    \While{$newCode \neq maxValue$}

      \If{$\NOT$ \Call{IsInTable}{$newCode$}}
        \Let{$string$}{\Call{tranlate}{oldCode}}
        \Let{$string$}{$string + character$}
      \Else
        \Let{$string$}{\Call{translate}{$newCode$}}
      \EndIf

      \State \Call{outputString}{$string$}

      \Let{$character$}{$string[0]$} \Comment{Get the first character
        of the translated string.}

      \State \Call{$AddToStringTable$}{$oldCode, character$}

      \Let{$oldCode$}{$newCode$}

      \Let{$newCode$}{\VoidCall{$ReadByte$}}

    \EndWhile
  \end{algorithmic}
\end{algorithm}


\section{Efficiency}

\subsection{The Canterbury Corpus}

As you may noticed doing LZW compression on small data is a very small
gain operation. However, doing this on larger files do actually yield a
significant decrease in file sizes.

In the chapter we introduce a set of test files we'll be using the
demonstrate the efficiency of compression algorithm. We'll be using a
corpus of files for testing new compression algortihms called the
Canterbury Corpus. These files we're selected out of thousands of
other files because they the best demonstrate the efficency of
compression algorithms \cite{arnold:corpus}. We'll also be using the
Large Corpus \cite{powell:desc-corp}.

Table \ref{tab:corp-files} summaries all the files we'll be using. They can all be
downloaded from \cite{powell:desc-corp}.

\todo{typesett the file names using typewriter font.}
\begin{table}
  \centering
  \begin{tabular}{ll}
    \toprule
    File & Category \\
    \midrule
    alice29.txt & English text \\
    asyoulik.txt & Shakespeare \\
    cp.html & HTML source \\
    fields.c & C source \\
    grammar.lsp & LISP source \\
    kennedy.xls & Excel Spreadsheet \\
    lcet10.txt & Technical writing \\
    plrabn12.txt & Poetry \\
    sum & SPARC Executable \\
    xargs.1 & GNU manual page \\
    E.coli & Complete genome of the E. Coli bacterium \\
    bible.txt & The King James version of the bible \\
    world192.txt & The CIA world fact book \\
    \bottomrule
  \end{tabular}
  \caption{}
  \label{tab:corp-files}
\end{table}

\subsection{The Test}

The test we will be doing in this section as that we will be testing
how the compression ratio of the LZW algorithm will be on these
different files. We'll also be testing how the compression ratio
varies with different sizes of the codes.

\subsection{The Test Results}

In table ? we show the results of the test.


\begin{table}
  \scriptsize
  \centering
  \noindent\makebox[\textwidth]{%
  \begin{tabular}{lllllllll}
    \toprule
    File & Original size & 9-bit codes(\%) & 10-bit codes(\%) & 11-bit codes(\%) & 12-bit codes(\%) & 13-bit codes(\%) & 14-bit codes(\%) & 15-bit codes(\%) \\
alice29.txt & 152089 & 68.9 & 57.9 & 51.1 & 47.6 & 45.0 & 43.4 & 43.3\\
asyoulik.txt & 125179 & 74.2 & 63.0 & 54.6 & 50.3 & 47.2 & 45.9 & 47.0\\
bible.txt & 4047392 & 62.2 & 54.7 & 50.2 & 45.7 & 42.7 & 39.7 & 37.6\\
cp.html & 24603 & 80.2 & 60.3 & 52.5 & 49.7 & 49.4 & 53.2 & 57.0\\
E.coli & 4638690 & 31.5 & 28.6 & 27.6 & 27.1 & 26.7 & 26.5 & 26.4\\
fields.c & 11150 & 77.7 & 63.4 & 52.7 & 47.7 & 51.7 & 55.6 & 59.6\\
grammar.lsp & 3721 & 63.9 & 55.4 & 52.1 & 56.9 & 61.6 & 66.4 & 71.1\\
kennedy.xls & 1029744 & 74.8 & 82.8 & 67.5 & 40.7 & 33.0 & 33.0 & 33.3\\
lcet10.txt & 426754 & 74.7 & 66.0 & 57.6 & 52.1 & 45.7 & 42.6 & 40.6\\
plrabn12.txt & 481861 & 69.8 & 59.2 & 53.7 & 48.8 & 45.8 & 44.0 & 42.6\\
sum & 38241 & 83.6 & 84.0 & 79.8 & 80.9 & 78.9 & 57.3 & 61.4\\
world192.txt & 2473400 & 81.3 & 71.0 & 67.0 & 63.4 & 52.5 & 46.2 & 41.5\\
xargs.1 & 4227 & 75.6 & 61.1 & 58.3 & 63.7 & 69.0 & 74.3 & 79.6\\
    \bottomrule
  \end{tabular}}
  \caption{LZW test results. The different percentages the represent the respective compression ratios of that code size.}
  \label{tab:corp-files}
\end{table}

\FloatBarrier

\printbibliography[heading=subbibliography]

\end{refsection}
