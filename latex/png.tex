\begin{comment}
  \bibliography{project.bib}
\end{comment}

% filters:
% http://www.libpng.org/pub/png/spec/1.0/PNG-Filters.html#Filter-type-2-Up
% http://www.libpng.org/pub/png/book/chapter09.html

\chapter{Portable Network Graphics}
\label{cha:png}

\newcommand{\chnk}[1]{``#1''}

\newcommand{\IDAT}{\chnk{IDAT}\xspace}

\section{History}

As stated in section \ref{sec:gif-history}, the creation of the PNG
format was primarily motivated by the patents encumbering the already
popular GIF format. To solve this problem, a bunch of developers in
the graphics developer community decided to cooperate on creating a
new format that came to be known as PNG. July 1 1996, version 1.0 of
the PNG specification was released. Then version 1.1 was released on
new years eve of 1998. And the latest version of the PNG specification
is version 1.2, which was released in August 1999.
\cite{roelofs09:_histor_portab_networ_graph_png_format,roelofs99:_png,roelofs:_portab_networ_graph_main}.

What follows is a technical description of the PNG format. It is based
on the references
\cite{boutel:_png_portab_networ_graph_specif_version12,roelofs99:_png,boutel:_png_portab_networ_graph_specif_version11}.

\section{Buildings Blocks}

\subsection{Chunks}

PNG images are fundamentally built up of chunks. The structure of the
chunk is shown in figure \ref{fig:png-chunk}. It consists of four so
called fields. Let us desribe them, one after one:

\begin{figure}
  \centering
  \inputtikz{png_chunk.tex}
  \caption{The PNG chunk datatype}
  \label{fig:png-chunk}
\end{figure}

\subsubsection*{Length (4 Bytes)}

This 32-bit number is used to store the byte length of the data
field.

\subsubsection*{Chunk Type (4 Bytes)}

This field stores 4 bytes that are used to store the type of the
chunk. Only the ASCII letters in the ranges A--Z and a--z are
acceptable values of these bytes. So \chnk{abcd} is an acceptable
chunk type while \chnk{a:e;} is not.

There is a convention used in the naming of chunks. If the first
letter in the type name of a chunk is uppercase, it is a
\textit{critical} chunk. If a critical chunk is found in a PNG image,
then it \textit{must} be loaded for the image to be successfully
displayed.  If such a chunk is not loaded, the program will not have
enough information to correctly render the image. Critical chunks and
their inner workings will for this reason be the main topic of this
chapter.

If on the other hand the first letter of the chunk type name is
lowercase, then that means that the chunk is \textit{ancillary}. These
chunks do not need to be loaded in order to successfully render the
image. These can contain all kinds of data, like the creation date of
the image or a textual comment. Since much of the kind of data stored
in ancillary chunks are things that we discussed in chapter
\ref{cha:gif} and \ref{cha:tga}, we will not discuss these chunks at
all.

\subsubsection*{Data (Variable)}

In this field the actual data of the chunk is stored. The length of
this field was specified by the earlier length field.

\subsubsection*{CRC (4 Byte)}

This is a CRC that is used to validate the correctness of the data in
the chunk field. The CRC used in this field is the one we discussed
back in section \ref{sec:pngcrc} on page \pageref{sec:pngcrc}

\subsection{PNG Signature}

Only chunks can be found in a PNG image with one exception: the PNG
signature. The PNG signature is a sequence of 8 bytes that is
\textit{always} found in the beginning of a legit PNG image. The byte
sequence is the numbers

\begin{equation*}
  \text{137 80 78 71 13 10 26 10}
\end{equation*}

They were all chosen to detect certain kinds of errors that can occur
when transmitting a PNG file over a network because such errors were
very normal back in the days when PNG was invented.

The first bit is $137$. In binary this number is $1000\ 1001$. The key
part to notice is that this is a non-ASCII character, because since
the 7:th bit toggled it will always have a value $\ge 128$. When data
is tranmitted as ASCII-text over a network the 7:th bit tends to be
thrown away, as it is for example done in STMP \cite{rfc5321}, the
Internet protocol that is used to transfer emails. To transmit
non-ASCII binary data, like image data is, one should instead use the
MIME protocol, which is an extension to the STMP protocol.

So the main purpose of the first byte is to detect whether an image
has accidentally been transmitted as ASCII text. If this byte doesn't
have its proper value, then the image has been corrupted. Then also
the bytes whose values are $\ge 128$ in the image file will also be
corrupted, so there's little to no point in the decoder trying to open
the corrupted image.

The bytes

\begin{equation*}
  \text{80 78 71}
\end{equation*}

are the ASCII values for the string PNG, so they could simply be seen
as the magic numbers of the PNG format.

The following two bytes are

\begin{equation*}
  \text{13 10}
\end{equation*}

This is a windows style new line, CRLF, as was discussed section in
\ref{sec:glossary} on page \pageref{sec:glossary}. If a PNG file is
accidentally transferred as text, there is another thing that may
corrupt the file: line ending conversions. When, for example, you are
transmitting a file from a window based operating system to a
UNIX-based operating system, there is a chance that the proram doing
the transmission may convert the windows-style line-endings to their
Unix equivalents, LF. But for a binary image file this behavior is
clearly undesirable, and is very likely to end up corrupting the image
data. To detect such errors, these two bytes are used.

The byte $26$ is a bit obscure and it basically does nothing to verify
the correctness of the file. We will for these reasons a omit
description of it here.

The last byte $10$ is the newline character in UNIX-based operating
systems, LF. So this is yet another byte that is used to verify that
the image was not transferred as text. This byte is used to verify
that an image transferred from a UNIX-based operating system to a
windows based operating system is not transferred as ASCII text.

\section{Critical Chunks}

Following the PNG signature is a sequence of chunks. Most kinds of
chunks can simply be ignored, but the critical ones can not be
ignored. Let us discuss the critical chunks, one after one.

\subsection{IHDR -- Image Header}

The image header of the PNG format, the \chnk{IHDR} chunk, is by the
PNG specification guaranteed to always occur first in a PNG file,
after the PNG signature. It contains data that is absolutely necessary
for loading the image data.

\subsubsection*{Width (4 Bytes)}
\subsubsection*{Height (4 Bytes)}

These two consecutive fields contains the size of the image. Since
they are stored in two 32-bit numbers each, this means that the PNG
format allows for quite huge images.

\subsubsection*{Bit Depth (1 Byte)}

In the bit depth field the \textit{size of each color channel} is
stored. So this value is \textit{not} the color depth of the
image. However, note the only the values 1, 2, 4, 8 and 16 are allowed
values for this field. This is mainly to simplify the job for
programmers using the PNG format.

\begin{table}
  \centering
  \begin{tabular}{l l}
    \toprule
    Color Type & Description \\
    \midrule
    0 & Grayscale color \\
    2 & Truecolor, meaning that RGB is used \\
    3 & Indexed color, meaning that a color palette is used \\
    4 & Grayscale with an alpha channel \\
    6 & Truecolor with alpha, meaning that RGBA is used \\
    \bottomrule
  \end{tabular}
  \caption{The different color types of the PNG format}
  \label{tab:png-color-type}
\end{table}

\subsubsection*{Color Type (1 Byte)}

The PNG format allows five different ways of storing color. The color
type used varies depending on this value, as is shown in table
\ref{tab:png-color-type}.

As you can from this field and the former, the PNG is very flexible
and allows for a multitude of different ways of storing
color. However, to simplify things for programmers, not all possible
bit depths can be used with all color types. The allowed color depths
are shown in table \ref{tab:png-color-type}.

\begin{table}
  \centering

  \newcommand{\invalid}{\cellcolor{gray}}

  \begin{tabular}{|l|l|l|l|l|l|l|}
    \hline
    \multicolumn{7}{|c|}{Color Depth} \\
    \cline{1-7}
    \multirow{2}{*}{Color Type} & \multirow{2}{*}{Channels} &
    \multicolumn{5}{c|}{Bits per channel} \\

    \cline{3-7}

    & & 1 & 2 & 4 & 8 & 16 \\

    \hline
    Indexed & 1 & 1 & 2 & 4 & 8 & \invalid \\ \hline
    Grayscale & 1 & 1 & 2 & 4 & 8 & 16  \\ \hline
    Grayscale and alpha & 2 & \invalid& \invalid & \invalid & 16 & 32  \\ \hline
    Truecolor & 3 & \invalid & \invalid & \invalid & 24 & 48  \\ \hline
    Truecolor and alpha & 4 & \invalid & \invalid & \invalid & 32 & 64  \\ \hline

    \hline

  \end{tabular}
  \caption{The allowed color depths of the PNG format.}
  \label{tab:png-color-depths}
\end{table}

\subsubsection*{Compression method (1 Byte)}

This field is used to indicate the compression method used in the
image data. But the only value defined for this field by the PNG
specification is $0$, which means that DEFLATE compression is used.

\subsubsection*{Filter Method (1 Byte)}

PNG also allows certain so-called filters to be applied to the image
data. These filters basically make the image data compress
better. Only the value $0$ is defined for this field, and this means
that the four default filters are used to perform the filtering. We'll
discuss the filters in section \ref{sec:png-filters}.

\subsubsection*{Interlace Method (1 Byte)}

If this field is $0$, then no interlacing is used in the image data; if it
is $1$, then the image data is interlaced.

The PNG format supports an interlacing method known Adam7, named so
because it was invented by Adam Costello. This method of interlacing
is significantly more complex than that of GIF's, and is something
that we will discuss in depth in section \ref{png-interlacing}.

\subsection{PLTE -- Image Palette}

If the image uses indexed color, then that means that it uses a
palette and that is what is stored in this chunk. The palette chunk
simply consists of a sequence of RGB colors. These colors will always be
24 bits of size, so 8 bits are assigned to each color channel.

\subsection{IDAT -- Image Data}

In this chunk the color data of the image is stored. The image data
storage system of the PNG format is very complex and it is discussed
in depth in section \ref{sec:png-image-data-storage}.

\subsection{IEND -- Image Trailer}

The reading of chunks from the PNG file will go and on until the image
trailer chunk, \chnk{IEND}, is found. Once this chunk is encountered
in the file, the entire image has been processed, and the decoder is
done. The chunk data of this chunk type will \textit{always} be empty.

\section{Image Data Storage Model}
\label{sec:png-image-data-storage}

We will now describe how the color data is stored in the IDAT chunk.

\subsection{The encoding process}

To understand how the color data is stored in the \IDAT chunk, we must
first understand how the data is encoded in the first place. So before
discussing the decoding process, we will now briefly discuss how the
image data is encoded.

The unencoded data is just a sequence of pixel color values. If the
image is \textit{interlaced}, then the image data is rearranged in a
certain order and divided into passes. This process is in the PNG
specification referred to as \textit{pass extraction}. We'll discuss
interlacing in section \ref{png-interlacing}.

Not all images are interlaced, and if not, then the image data is just
carried onto the next step. The next step is known as \textit{scanline
  serialization}. Here, the separate colors are partitioned up into
byte values, and the byte values are divided up into separate rows.

\newcommand{\checkerimg}{
  \tikz[scale=2]{
    \fill[gray] (0,0) rectangle (0.5ex,0.5ex);
    \fill[black] (0.5ex,0) rectangle (1.0ex,0.5ex);
    \fill[black] (0,0.5ex) rectangle (0.5ex,1.0ex);
    \fill[gray] (0.5ex,0.5ex) rectangle (1.0ex,1.0ex);
  }}

It is important to understand how exactly the scanline serialization
is done. Say I have an image with the size 2x2, meaning that it is two
pixels wide and two pixels high. This image uses indexed color with a
color depth of 1 to store the color. Let the index $0$ represent a
fully black color and the index $1$ represent gray color. Now let's
that the first row of this image consists of the color indexes $1$ and
$0$ and that the second consists of the indexes $0$ and $1$. Then this
data would represent the image \checkerimg. Then, after scanline
serialization process, the first row of this image will get encoded as
a byte by writing from the highest bits to the lowest, meaning that
the resulting byte will be $128$. The bit pattern for this number
\bin{\textbf{10}00\ 0000}. Separate rows in the image data are kept
separate from each other, so the second row will get encoded in a
separate byte value $64$(\bin{\textbf{01}00\ 0000}).

If on the other hand the color depth was 2, and the color values of
the indexes of the data were kept the same, $01$; $00$; $00$; $01$,
then the data would have been encoded as the bytes
$64$(\bin{\textbf{0100}\ 0000}) and $16$(\bin{\textbf{0001}\ 0000}).

Grayscale color is dealt with in very much the same way as indexed
color. The miscellaneous color types are often too big to fit in a
single byte, so the separate channel values are spread out over
consecutive bytes. If the channels sizes are over 8 bits, then also
the channels will get spread out over several bytes.

After the scanline serialization process, filters are applied to the
image data that is now represented as a sequence of bytes. The filters
are operations on the byte sequence that makes the data easier to
compress. We'll discuss these filters in section
\ref{sec:png-filters}.

After that the data has optimized for compression by the filter, it is
compressed using the DEFLATE algorithm, and stored using the ZLIB
format. We'll discuss this in more depth in section \ref{sec:png-dec}.

And after all these steps, the image data is finally divided into
\IDAT chunks, and these chunks are written to the file.

And that is the entire encoding process. It is, indeed, compared to
that of the other formats we have described, one complicated process.

To undo this entire process the separate subprocesses has to be
reversed in the reverse order that they were done. So let us start by
describing how to undo the last of these subprocesses.

\subsection{Consecutive Chunks}

First of all, even though the chunk length is stored in a 32-bit
number, one chunk may not be enough to store all the compressed image
data. If so, then the compressed image data is split up over several
\IDAT chunks. So if an \IDAT chunk is encountered, one should keep
reading and concatenate the data found in the \IDAT chunks until a non
\IDAT chunk is found. Then, before reading the next chunk, one should
decode and deal with the image data.

\subsection{Decompression}
\label{sec:png-dec}

The compressed image data, which may or may not be split up over
several \IDAT chunks, is stored using the ZLIB format. Let us briefly
outline the structure of this format, as it is specified by
\cite{gailly96:_zlib_compr_data_format_specif}:

\subsubsection{CMF}

The first value found in the ZLIB format will always be the CMF
byte. It is divided into two subfields:

\paragraph{Bits 0-3 -- CM}

The 4 lowest bits is the CM value. It is used to indicate the
compression method. The only valid value of this field is $8$, which
means that the compression method DEFLATE is used. We discussed
DEFLATE in chapter \ref{cha:deflate}.

\paragraph{Bits 4-7 -- CINFO}

The compression info. It is the base 2 logarithm, $\log_2$, of the
LZ77 window size used during the DEFLATE compression, minus $8$ . Its
maximum value is $7$, meaning that the maximum possible size of the LZ77 window
will be $2^{7 + 8} = 2^{15} = 32768$.

\subsection{Filtering}
\label{sec:png-filters}

The main purpose of the filters is to make the image data easier to
compress. So their purpose is not to actually compress the image data.

In the filtering step, some sort of operation is performed on
\textit{every row} of the image data. At the beginning of every row,
the identifying number of the filter applied on that row is then
given. If for the example, after a has the been filtered, the data is
$23,12,11$, and the filter had the identifying number $2$, then the
resulting filtered row is $2,23,12,11$. There are five different
filter types, and we will now discuss them one by one:

\subsubsection{Filter 0 -- None}

Henceforth, we will let $B_{i,j}$ represent the \textit{byte} that
being filtered by a filter. This byte is the $j$:th byte in row $i$ of
the color data. Notice that we do not reference the separate pixels
using notation. Filters operate on bytes instead of pixels for reasons
that we will explain later.



The first filter has the simple name None. This filter does nothing to
the row image data at all. So a row containing the data $1,2,3$ will
simply get filtered to the row $0,1,2,3$ by this filter. This filter
is mainly applied to rows in the image data where no filter can be
used to effectively increase the compression rate.

\subsubsection{Filter 1 -- Sub}

Now it is time to describe a filter that actually does
something. Consider the data sequence

\begin{equation}
  \label{eq:1-seq}
  1,2,3,\dots,254,255
\end{equation}

Assuming that we are using 8-bit grayscale color, this data sequence
describes a slow but steady progression from black to white. This
linear kind of color progression is in computer graphics known as a
\textit{gradient}\cite{sayood2003lossless}. How this progression would
look like in an actual image, is demonstrated in figure
\ref{fig:gradient-black-white}. The key part here is to notice that
since the difference between each number is always $1$,

\begin{equation*}
  2-1=3-2=4-3=\dots=255-254=1,
\end{equation*}

the data can also be represented
like this

\begin{equation}
  \label{eq:filter1-seq}
  1,1,1,\dots,1,1
\end{equation}

So every byte $B_{i,j}$ in the image will be represented by the
difference $B_{i,j} - B_{i,j-1}$. If $j \le 0$, then always $B_{i,j-1}
= 0$, so all bytes outside the boundary of the image will always be
equal to $0$. All subtraction and addition is done modulo $256$. And
since bytes store contain negative numbers, numbers like $-2$ will be stored as
$254$.

The original sequence can then be restored by iterating over the
sequence (\ref{eq:filter1-seq}) and keeping a running sum, like this:

\begin{equation*}
  0+1,1+1,1+1+1,\dots
\end{equation*}

So each unfiltered byte is calculated from the filtered data $B$ in
this way:  $B_{i,j} + B_{i,j-1}$. And remember that all addition is
done modulo $256$

This filter can increase greatly the compression rate, because surely
the sequence given in \ref{eq:filter1-seq} is easier to compress than
the one given in \ref{eq:1-seq}. Yes, because in the filtered sequence
redundancies are abundant, while in the unfiltered sequence not a
single redundancy can be found! In fact, even an extremely simple
compression algorithm like RLE can do wonders compressing this data.

Now consider figure \ref{fig:gradient-blue-red}. Assuming 24-bit
color, it is a gradient from the bluest of blue, $(0,0,255)$, to the
reddest of red, $(255,0,0)$. This gradient is expressed by the
following sequence of RGB triplets

\begin{equation*}
  (0,0,255), (1,0,254), (2,0,253), \dots, (254,0,1), (255,0,0)
\end{equation*}

In memory, this data laid out as sequence of 8-bit bytes. However, can
we filter this row for better compression using the same method we
described before for 8-bit grayscale data? No, because the
redundancies lies in the difference between the color channels
\textit{of different colors}, not between the separate color channels
that describes the separate colors.

So the method of calculating each filtered byte to $B_{i,j} -
B_{i,j-1}$ will not work very well. Rather, it should be calculated
like $B_{i,j} - B_{i,j-3}$, because every 24-bit color has $3$
channels in 24-bit color.

Generally, for every color type, there is some value $t$ that is to
calculate the filtered byte $B_{i,j} - B_{i,j-t}$. By the PNG
specification this value is defined as

\begin{equation*}
  t = \left\lceil \frac{c}{8} \right\rceil
\end{equation*}

Where $c$ is the number of bits per channel. Notice that by this
definition this, this filter will not operate pixels but on bytes. For
1-bit grayscale color, here $c=1$, will be $t=1$, despite the fact
that a whole $8$ pixels can fit in a byte. The developers of the PNG
specification made this decision to simplify the work of implementing
support for these filters. All the other filters will also operate on
bytes for this reason.

Even for color types where the color channels are stored in channels
of sizes over $8$ bits the filters will always operate on bytes. For
48-bit color, where 16 bits are assigned to every channel, $t=6$. So
for the red channel of a color, the value of the 8 highest bits, seen
as a single byte, will be substracted the value of the of the 8
highest bits of the former pixel. The same things is done for the 8
lower bits.

\begin{figure}[h!]
  \centering
  \subfloat[][From black to white.]{
    \begin{tikzpicture}
      \shade[left color=black,right color=white] (0,0) rectangle (6,0.5);
    \end{tikzpicture}
    \label{fig:gradient-black-white}}

  \subfloat[][From blue to red.]{
    \begin{tikzpicture}
      \shade[left color=blue,right color=red] (0,0) rectangle (6,0.5);
    \end{tikzpicture}
    \label{fig:gradient-blue-red}}

  \caption{Examples of gradients}
\end{figure}

\begin{Exercise}[label={filter-1}]

  Filter the rows of the following image using filter type 1(remember
  that every filtered row must begin with the filter type):

\[
 \begin{matrix}
  2 & 3 & 4 & 5 \\
  4 & 9 & 14 & 19 \\
  2 & 12 & 3 & 20
 \end{matrix}
\]

The color type is $0$, and the number of bits per channel is $8$.

% add more exercises, with 24-bit color and exercises showing
% subgradient in image.

\end{Exercise}

\subsubsection{Filter 2 -- Up}

The up filter works just like the Sub filter, expect that its purpose
is to make horizontal gradient easier to compress rather than vertical
gradients. So every byte will be filtered as $B_{i,j} - B_{i-1,j}$;
that is, every byte is subtracted from the value of the corresponding
byte in the former, unfiltered row. This filter, just as the former,
operates only on bytes and not on pixels.

So given the three rows

\[
 \begin{matrix}
  4 & 5 \\
  5 & 9 \\
  6 & 13 \\
 \end{matrix}
\]

If we let the first row get filtered by filter $0$, and the last two
rows get filtered by filter $2$, then these rows will be filtered as
follows

\[
 \begin{matrix}
  0 & 4 & 5 \\
  2 & 1 & 4 \\
  2 & 1 & 4 \\
 \end{matrix}
\]

While it is true that the DEFLATE algorithm is one dimensional(it
operates on the data as a long sequence of bytes), this filter has the
positive effect that it also increase the redundancy of the data to be
compressed. So it is not as useless as it may seem.

\subsubsection{Filter 3 -- Average}

This filter is essentially a combination of the two former
filters. Here the filtered value of the byte will be equal to the
value of the unfiltered byte subtracted from the average of the upper
and former byte,

\begin{equation*}
  B_{i,j} - \left \lfloor \frac{B_{i-1,j} +
    B_{i,j-t}}{2} \right \rfloor
\end{equation*}

So the average is rounded down. However, do note that the sum $B_{i-1,j} +
    B_{i,j-t}$ is \textit{not} done modulo $256$.

The transformation can then trivially reversed as follows

\begin{equation*}
  B_{i,j} + \left \lfloor \frac{B_{i-1,j} +
    B_{i,j-t}}{2} \right \rfloor
\end{equation*}

%% exlpain why filter works and why the above addition mustn't be done
%% modulo 256.

\subsubsection{Filter 4 -- Paeth}

In this filter third byte is added for the computation: the preceding
byte of the upper byte, $B_{i-1,j-t}$. The filtered byte in this
filter computed as follows:

\begin{equation*}
  B_{i,j} - \textsc{Paeth}(B_{i,j-t},B_{i-1,j},B_{i-1,j-t})
\end{equation*}

Where \textsc{Paeth} is the so-called Paeth-predictor function, named
after Alan W.~Paeth because it was first described by him in
\cite{arvo1994graphics_gems}. It is defined as is shown in algorithm,
where $a=B_{i,j-t}$, $b=B_{i-1,j}$ and $c=B_{i-1,j-t}$.


\begin{algorithm}[H]
  \caption{The Paeth filter.}
  \label{alg:paeth}
  \begin{algorithmic}[1]
    \Procedure{Paeth}{$a,b,c$}
    \Let{$\var{estimate}$}{$a+b-c$}
    \Let{$\Delta a$}{$|\var{estimate}-a|$}
    \Let{$\Delta b$}{$|\var{estimate}-b|$}
    \Let{$\Delta c$}{$|\var{estimate}-c|$}
    \linecomment{Return the delta closest to the estimate.}
    \If{$\Delta a \le \Delta b \AND \Delta a \le \Delta c $}
    \State \Return{$\Delta a$}
    \ElsIf{$\Delta b \le \Delta c$}
    \State \Return{$\Delta b$}
    \Else
    \State \Return{$\Delta c$}
    \EndIf
    \EndProcedure
  \end{algorithmic}
\end{algorithm}


\subsection{Scanline serialization}

\subsection{Interlaced Color Data}
\label{png-interlacing}

\section{Answers to the exercises}

\begin{Answer}[ref={filter-1}]

\[
 \begin{matrix}
  1 & 2 & 1 & 1 & 1 \\
  1 & 4 & 5 & 5 & 5 \\
  1 & 2 & 10 & 247 & 17
 \end{matrix}
\]


\end{Answer}

% mention private chunks like imagemagick's  vpag

% quickly summarize the ones that won't get in depth coverage.