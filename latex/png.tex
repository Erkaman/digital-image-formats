\begin{comment}
  \bibliography{project.bib}
\end{comment}

\chapter{Portable Network Graphics}
\label{cha:png}

\newcommand{\chnk}[1]{``#1''}

\section{History}

As stated in section~\ref{sec:gif-history}, the creation of the \png
format was primarily motivated by the patents encumbering the already
popular \gif format. To solve this problem, a bunch of developers in
the graphics developer community decided to cooperate on creating a
new format that came to be known as \png.
\cite{roelofs09:_histor_portab_networ_graph_png_format,roelofs99:_png,roelofs:_portab_networ_graph_main}.

What follows is a technical description of the \png format. It is based
on the references
\cite{boutel:_png_portab_networ_graph_specif_version12,roelofs99:_png,boutel:_png_portab_networ_graph_specif_version11}.

\section{Buildings Blocks}

\subsection{Chunks}

\png images are fundamentally built up of chunks. The structure of the
chunk is shown in figure~\ref{fig:png-chunk}. It consists of four
fields. Let us desribe them, one after one:

\begin{figure}
  \centering
  \inputtikz{png_chunk.tex}
  \caption{The \png chunk datatype}
  \label{fig:png-chunk}
\end{figure}

\subsubsection*{Length (4 Bytes)}

This 32-bit number is used to store the byte length of the data
field.

\subsubsection*{Chunk Type (4 Bytes)}

This field stores 4 bytes that are used to define the type of the
chunk. Only the \ascii letters in the ranges A--Z and a--z are
acceptable values of these bytes. So \chnk{abcd} is an acceptable
chunk type while \chnk{a:e;} is not.

There is a convention used in the naming of chunks. If the first
letter in the type name of a chunk is uppercase, it is a
\textit{critical} chunk. If a critical chunk is found in a \png image,
then it \textit{must} be loaded for the image to be successfully
displayed.  If such a chunk is not loaded, the program will not have
enough information to correctly render the image. Critical chunks and
their inner workings will for this reason be the main topic of this
chapter.

If on the other hand the first letter of the chunk type name is
lowercase, then that means the chunk is \textit{ancillary}. These
chunks do not need to be loaded in order to successfully render the
image. These can contain all kinds of data, like the creation date of
the image or a textual comment. Since much of the kind of data stored
in ancillary chunks are things that we discussed in
chapter~\ref{cha:gif}~and~\ref{cha:tga}, we will not discuss these
chunks at all.

\subsubsection*{Data (Variable)}

In this field the actual data of the chunk is stored. The length of
this field was specified by the earlier length field.

\subsubsection*{CRC (4 Bytes)}

This is a \crc that is used to validate the correctness of the data in
the chunk field. The \crc used in this field is the one we discussed
back in section~\ref{sec:pngcrc} on page~\pageref{sec:pngcrc}.

\subsection{PNG Signature}

Only chunks can be found in a \png image with one exception: the \png
signature. The \png signature is a sequence of 8 bytes that is
\textit{always} found in the beginning of a legit \png image. The
signature itself consists of the bytes

\begin{equation*}
  \text{137 80 78 71 13 10 26 10}
\end{equation*}

They were all chosen to detect certain kinds of errors that can occur
when transmitting a \png file over a network because such errors were
very normal back in the days when \png was invented.

The first byte is $137$. In binary this number is \bin{1000\ 1001}. The key
part to notice is that this is a non-\ascii character, because since
the 7:th bit toggled it will always have a value $\ge 128$. When data
is tranmitted as \ascii-text over a network the 7:th bit tends to be
thrown away, as it is for example done in \stmp \cite{rfc5321}, the
Internet protocol that is used to transfer emails. To transmit
non-\ascii binary data, like image data is, one should instead use the
\mime protocol, which is an extension to the \stmp protocol.

So the main purpose of the first byte is to detect whether an image
has accidentally been transmitted as \ascii text. If this byte does not
have its proper value, then the image has been corrupted. Then also
the bytes whose values are $\ge 128$ in the image file will also be
corrupted, so there is little to no point in the decoder trying to open
the corrupted image.

The bytes $80, 78, 71$ are the \ascii values for the string \png, so
they could simply be seen as the magic numbers of the \png format.

The following two bytes are $13, 10$. This is a windows style new
line, \crlf, as was discussed section in~\ref{sec:glossary} on page~\pageref{sec:glossary}. If a \png file is accidentally transferred as
text, there is another thing that may corrupt the file: line ending
conversions. When, for example, you are transmitting a file from a
window based operating system to a Unix-based operating system, there
is a chance that the proram doing the transmission may convert the
windows-style line-endings to their Unix equivalents, \lf. But for a
binary image file this behavior is clearly undesirable, and is very
likely to end up corrupting the image data. To detect such errors,
these two bytes are used.

The byte $26$ is very obscure and it basically does nothing to verify
the correctness of the file. We will for these reasons a omit
description of it here.

The last byte $10$ is the newline character in Unix-based operating
systems, \lf. So this is yet another byte that is used to verify that
the image was not transferred as text. This byte is used to verify
that an image transferred from a Unix-based operating system to a
windows based operating system is not transferred as \ascii text.

\section{Critical Chunks}

Following the \png signature is a sequence of chunks. Most kinds of
chunks can simply be ignored, but the critical ones can not be
ignored. Let us discuss the critical chunks, one after one.

\subsection{Image Header}

The image header of the \png format, the \ihdr chunk, is by the
\png specification guaranteed to always occur first in a \png file,
after the \png signature. It contains data that is absolutely necessary
for loading the image data.

\subsubsection*{Width (4 Bytes)}
\subsubsection*{Height (4 Bytes)}

These two consecutive fields contains the size of the image.

\subsubsection*{Bit Depth (1 Byte)}

In the bit depth field the \textit{size of each color channel} is
stored. So this value is \textit{not} the color depth of the
image. However, note that only the values 1, 2, 4, 8 and 16 are
allowed values for this field. This is mainly to simplify the job for
programmers using the \png format.

\begin{table}
  \centering
  \begin{tabular}{l l}
    \toprule
    Color Type & Description \\
    \midrule
    0 & Grayscale color \\
    2 & Truecolor, meaning that \rgb is used \\
    3 & Indexed color, meaning that a color palette is used \\
    4 & Grayscale with an alpha channel \\
    6 & Truecolor with alpha, meaning that \rgba is used \\
    \bottomrule
  \end{tabular}
  \caption{The different color types of the \png format}
  \label{tab:png-color-type}
\end{table}

\subsubsection*{Color Type (1 Byte)}

The \png format allows five different ways of storing color. The color
type used varies depending on this value, as is shown in
table~\ref{tab:png-color-type}.

As you can from this field and the former, the \png is very flexible
and allows for a multitude of different ways of storing
color. However, to simplify things for programmers, not all possible
bit depths can be used with all color types. The allowed color depths
are shown in table~\ref{tab:png-color-depths}.

\begin{table}
  \centering

  \begin{tabular}{lllllll}
    \toprule
    \multicolumn{7}{c}{Color Depth} \\
    \cline{1-7}
    \multirow{2}{*}{Color Type} & \multirow{2}{*}{Channels} &
    \multicolumn{5}{c}{Bits per channel} \\

    \cline{3-7}

    & & 1 & 2 & 4 & 8 & 16 \\

    \hline
    Indexed & 1 & 1 & 2 & 4 & 8 & \\
    Grayscale & 1 & 1 & 2 & 4 & 8 & 16  \\
    Grayscale and alpha & 2 &&&& 16 & 32  \\
    Truecolor & 3 &&&& 24 & 48  \\
    Truecolor and alpha & 4 &&&& 32 & 64  \\

    \bottomrule

  \end{tabular}
  \caption{The allowed color depths of the \png format}
  \label{tab:png-color-depths}
\end{table}

\subsubsection*{Compression method (1 Byte)}

This field is used to indicate the compression method used in the
image data. But the only value defined for this field by the \png
specification is $0$, which means that \deflate compression is used.

\subsubsection*{Filter Method (1 Byte)}

\png also allows certain so-called filters to be applied to the image
data. These filters basically make the image data compress
better. Only the value $0$ is defined for this field, and this means
that the four default filters are used to perform the filtering. We will
discuss the filters in section~\ref{sec:png-filters}.

\subsubsection*{Interlace Method (1 Byte)}

If this field is $0$, then no interlacing is used in the image data; if it
is $1$, then the image data is interlaced.

The \png format supports an interlacing method known Adam7, named so
because it was invented by Adam Costello. This method of interlacing
is significantly more complex than that of \gif, and is something
that we will discuss in depth in section~\ref{png-interlacing}.

\subsection{Image Palette}

For storing the palette the \plte chunk is used. The palette chunk
simply consists of a sequence of \rgb colors with a color depth of 24.

\subsection{Image Data}

Storage of the the compressed image data is handled by the \idat chunk. In
this chunk the color data of the image is stored. The image data
storage system of the \png format is very complex and it is discussed
in depth in section~\ref{sec:png-image-data-storage}.

\subsection{Image Trailer}

The reading of chunks from the \png file will go and on until the
image trailer chunk, the \iend chunk, is found. Once this chunk is
encountered in the file, the entire image has been processed, and the
decoder is done. The chunk data of this chunk type will
\textit{always} be empty.

\section{Image Data Storage Model}
\label{sec:png-image-data-storage}

We will now describe how the color data is stored in the \idat chunk.

\subsection{The encoding process}

To understand how the color data is stored in the \idat chunk, we must
first understand how the data is encoded in the first place, so we
will now briefly discuss the encoding process.

The unencoded data is just a sequence of pixel color values. If the
image is \textit{interlaced}, then the image data is rearranged in a
certain order and divided into passes. This process is in the \png
specification referred to as \textit{pass extraction}. We will discuss
interlacing in section~\ref{png-interlacing}.

Not all images are interlaced, and if not, then the image data is just
carried onto the next step. The next step is known as \textit{scanline
  serialization}. Here, the separate colors are partitioned up into
byte values, and the byte values are divided up into separate rows.

After this, filters are applied to the image data that is now
represented as a sequence of bytes. The filters are operations on the
byte sequence that makes the data easier to compress. We will discuss
these filters in section~\ref{sec:png-filters}.

After that the data has optimized for compression by the filter, it is
compressed using the \deflate algorithm, and stored using the \zlib
format. We will discuss this in more depth in section~\ref{sec:png-dec}.


And after all these steps, the image data is finally divided into
\idat chunks, and these chunks are written to the file.

And that is the entire encoding process. It is, indeed, compared to
that of the other formats we have described, one complicated process.

To undo this entire process the separate subprocesses has to be
reversed in the reverse order that they were done. So let us start by
describing how to undo the last of these subprocesses.

\subsection{Consecutive Chunks}

First of all, even though the chunk length is stored in a 32-bit
number, one chunk may not be enough to store all the compressed image
data. If so, then the compressed image data is split up over several
\idat chunks. So if an \idat chunk is encountered, one should keep
reading and concatenate the data found in the \idat chunks until a non
\idat chunk is found.

\subsection{Decompression}
\label{sec:png-dec}

The compressed image data, which may or may not be split up over
several \idat chunks, is stored using the \zlib format. Let us briefly
outline the structure of this format, as it is specified by
\cite{gailly96:_zlib_compr_data_format_specif}:

\subsubsection{CMF}

The first value found in the \zlib format will always be the \cmf
byte. It is divided into two subfields:

\paragraph{Bits 0-3 -- CM}

The 4 lowest bits is the \cm value. It is used to indicate the
compression method. The only valid value of this field is $8$, which
means that the compression method \deflate is used. We discussed
\deflate in chapter~\ref{cha:deflate}.

\paragraph{Bits 4-7 -- CINFO}

The compression info. It is the base 2 logarithm, $\log_2$, of the
size of the \lzone window used during the \deflate compression, minus
$8$ . Its maximum value is $7$, meaning that the maximum possible size
of the \lzone window will be $2^{7 + 8} = 2^{15} = 32768$.

\subsubsection{FLG}

The second value is the \flg byte. It divided into subfields as
follows:

\paragraph{Bits 0-4 -- FCHECK}

This value serves as a sort of checksum on the \cmf and \flg bytes. This
value must be the value such that

\begin{equation*}
  \text{\cmf} \cdot 256 + \text{\flg} (\bmod 31) = 0
\end{equation*}

so \cmf and \flg, when viewed as a 16-bit number, must be made dividable
by $31$ by this value. This value can \textit{always} do this because
the maximum value of a 5-bit number is $2^5 - 1 = 31$.

\paragraph{Bits 5 -- FDICT}

This value must always be $0$ for valid \png files.

\paragraph{Bits 6-7 -- FLEVEL}

Compression level. This value is used to indicate the compression
method used during the \deflate compression. It has $4$ possible
values:

\begin{description}
\item[0] Fastest compression algorithm used.
\item[1] Fast compression algorithm used.
\item[2] Default compression algorithm used.
\item[3] Maximum compression algorithm used.
\end{description}

What compression method was used depends on how aggressive the \lzone
window matching was during the \deflate compression. Because searching
the \lzone window for matches is such a slow
operation(\textit{especially} for very large windows), faster versions
of \deflate may give up on the string matching after a couple of tries
in order to speed up the compression in favor of lost compression
performance. However, the maximum compression algorithm will never
give up until it has searched the entire window for matches, and it
will therefore result in the best possible \deflate compression in
return for a speed loss. But with the fast computers of today the
maximum compression algorithm is almost always used, but back in the
old days you always had to make this choice between speed and
compression performance.

\subsubsection{Compressed Data}

Following the \flg byte the \deflate compressed data can be found,
which we discussed in chapter~\ref{cha:deflate}.

\subsubsection{Adler-32 checksum}

This is the Adler-32 checksum of the \textit{uncompressed data}. This
value is used validate the integrity of the uncompressed data. We
discussed the Adler-32 checksum in section~\ref{sec:adler32} on page~\pageref{sec:adler32}.

\subsection{Filtering}
\label{sec:png-filters}

Before the color data was compressed it was filtered. The main purpose
of the filters is to make the image data more susceptible to
compression.

In the filtering step, some sort of operation is performed on
\textit{every row} of the image data. A number is put at the beginning
of every filtered row to indicate the kind of filtering used. So the
row filtered down to $23,12,11$ by the filter $2$ will be represented
by $2, 23,12,11$. There are five different filter types, and we will
now discuss them one by one:

\subsubsection{Filter 0 -- None}

Henceforth, we will let $B_{i,j}$ represent the \textit{byte} that
being filtered by a filter. This byte is the $j$:th byte in row $i$ of
the color data. As familiar, the scanline serialization process that
occured before the filtering divided the pixel values into
bytes. Notice that we do not reference the separate pixels using this
notation. Filters operate on bytes instead of pixels for reasons that
we will explain later.

The first filter has the simple name None. This filter does nothing to
the row image data at all. So a row containing of the data $1,2,3$
will simply get filtered to the row $0,1,2,3$ by this filter. This
filter is mainly applied to rows in the image data where no filter can
be used to effectively increase the compression rate.

\subsubsection{Filter 1 -- Sub}

Now it is time to describe a filter that actually does
something. Consider the data sequence

\begin{equation}
  \label{eq:1-seq}
  1,2,3,\dots,254,255
\end{equation}

Assuming that we are using 8-bit grayscale color, this data sequence
describes a slow but steady progression from black to white(reread
section~\ref{sec:grayscale-color} on
page~\pageref{sec:grayscale-color} if you do not understand
this). This linear kind of color progression is in computer graphics
known as a \textit{gradient}\cite{sayood2003lossless}. How this
progression would look like in an actual image is demonstrated in
figure~\ref{fig:gradient-black-white}. The key part here is to notice
that since the difference between each number is always $1$,

\begin{equation*}
  2-1=3-2=4-3=\dots=255-254=1,
\end{equation*}

the data can also be represented
like this

\begin{equation}
  \label{eq:filter1-seq}
  1,1,1,\dots,1,1
\end{equation}

So every byte $B_{i,j}$ in the image will be represented by the
difference

\begin{equation*}
 B_{i,j} - B_{i,j-1}
\end{equation*}

If $j \le 0$, then always $B_{i,j-1} = 0$, so all bytes outside the
boundary of the image will always be equal to $0$. Since this is done
on bytes, all subtraction and addition is done modulo $256$. And since
bytes cannot store negative numbers, numbers like $-2$ will be stored
as $254$.

The original sequence can then be restored by iterating over the
sequence~\ref{eq:filter1-seq} and keeping a running sum:

\begin{equation*}
  0+1,1+1,1+1+1,\dots
\end{equation*}

So each unfiltered byte is calculated from the filtered data $B$ as
follows:

\begin{equation*}
  B_{i,j} + B_{i,j-1}
\end{equation*}

And remember that all addition is done modulo $256$.

This filter can increase greatly the compression rate, because the
sequence given in~\ref{eq:filter1-seq} is more susceptible to
compression than the original sequence~\ref{eq:1-seq}. This is because
in the filtered sequence redundancies are abundant, while in the
unfiltered sequence not a single redundancy can be found! In fact,
even an extremely simple compression algorithm like \rle can do wonders
compressing the filtered data.

Now consider figure~\ref{fig:gradient-blue-red}. Assuming 24-bit
color, it is a gradient from the bluest of blue, $(0,0,255)$, to the
reddest of red, $(255,0,0)$. This gradient is expressed by the
following sequence of \rgb triplets:

\begin{equation*}
  (0,0,255); (1,0,254); (2,0,253); \dots; (254,0,1); (255,0,0)
\end{equation*}

In memory, this data laid out as sequence of 8-bit bytes. However, can
we filter this row for better compression using the same method we
described before for 8-bit grayscale data? No, because the
redundancies lies in the difference between the \textit{color
  channels} of following colors, not between the separate color
channels that belong to the same color.

So the method of calculating each filtered byte to $B_{i,j} -
B_{i,j-1}$ will not work very well. Rather, it should be calculated as
$B_{i,j} - B_{i,j-3}$, since $24 / 8 = 3$.

Generally, for every color type and color depth, there is some value
$t$ that is used to calculate the filtered byte $B_{i,j} -
B_{i,j-t}$. For a color type where the number of bits per pixel, the
color depth, is $c$, this value is calculated as follows:

\begin{equation*}
  t = \left\lceil \frac{c}{8} \right\rceil
\end{equation*}

Notice that by this definition, since $t$ is rounded up to whole
bytes, this filter will not operate pixels but on bytes. For 1-bit
grayscale color, here $c=1$ and so $t=1$, despite the fact that a
whole $8$ pixels can fit in a byte. The developers of the \png
specification made this decision to simplify the work of implementing
support for these filters. All the other filters will also operate on
bytes for the same reason.

Even for color types where the color channels are stored in channels
of sizes over $8$ bits the filters will always operate on bytes. For
48-bit \rgb color, where 16 bits are assigned to every channel,
$t=6$. So for the red channel of such a color type, the value of the 8
highest bits is seen as a single byte and will be subtracted from the
value of the of the 8 highest bits of the red channel of the previous
pixel. The same thing is done for the 8 lower bits.

\begin{figure}[h!]
  \centering
  \subfloat[][From black to white.]{
    \begin{tikzpicture}
      \shade[left color=black,right color=white] (0,0) rectangle (6,0.5);
    \end{tikzpicture}
    \label{fig:gradient-black-white}}

  \subfloat[][From blue to red.]{
    \begin{tikzpicture}
      \shade[left color=blue,right color=red] (0,0) rectangle (6,0.5);
    \end{tikzpicture}
    \label{fig:gradient-blue-red}}

  \caption{Examples of gradients}
\end{figure}

So to summarize, the filtered bytes are calculated using the Sub
filter as follows:

\begin{equation*}
  B_{i,j} - B_{i,j-t}
\end{equation*}

And the bytes are unfiltered as

\begin{equation*}
  B_{i,j} + B_{i,j-t}
\end{equation*}

Where any values outside of the image boundaries are set to $0$.

\begin{Exercise}[label={filter-1}]

  Filter the rows of the following image data using filter type
  1(remember that every filtered row must begin with the filter type):

  \[
  \begin{matrix}
    2 & 3 & 4 & 5 \\
    4 & 9 & 14 & 19 \\
    2 & 12 & 3 & 20
  \end{matrix}
  \]

  The color type is $0$, and the number of bits per channel is $8$.

\end{Exercise}

\subsubsection{Filter 2 -- Up}

The Up filter works just like the Sub filter, expect that its purpose
is to make vertical gradients easier to compress rather than
horizontal. So every byte will be filtered as $B_{i,j} - B_{i-1,j}$;
that is, every byte is subtracted from the value of the corresponding
byte in the former row. This filter, just as the former, operates only
on bytes and not on pixels.

So given the three rows

\[
\begin{matrix}
  4 & 5 \\
  5 & 9 \\
  6 & 13 \\
\end{matrix}
\]

If we let the first row get filtered by filter $0$, and the last two
rows get filtered by filter $2$, then these rows will be filtered as

\[
\begin{matrix}
  0 & 4 & 5 \\
  2 & 1 & 4 \\
  2 & 1 & 4 \\
\end{matrix}
\]

Unfiltering is trivially done:

\begin{equation*}
  B_{i,j} + B_{i-1,j}
\end{equation*}

\subsubsection{Filter 3 -- Average}

This filter is essentially a combination of the two former
filters. Here the filtered value of the byte will be equal to the
average of $B_{i-1,j}$ and $B_{i,j-t}$, so it is calculated as

\begin{equation*}
  B_{i,j} - \left \lfloor \frac{B_{i-1,j} +
      B_{i,j-t}}{2} \right \rfloor
\end{equation*}

However, do note that the \png specification for requires that the sum
$B_{i-1,j} + B_{i,j-t}$ is \textit{not} done modulo $256$.

The transformation can then be trivially reversed:

\begin{equation*}
  B_{i,j} + \left \lfloor \frac{B_{i-1,j} +
      B_{i,j-t}}{2} \right \rfloor
\end{equation*}

\subsubsection{Filter 4 -- Paeth}

In this filter a third byte is added to the computation: the preceding
byte of the upper byte, $B_{i-1,j-t}$. The filtering computation is

\begin{equation*}
  B_{i,j} - \textsc{Paeth}(B_{i,j-t},B_{i-1,j},B_{i-1,j-t})
\end{equation*}

Where \textsc{Paeth} is the so-called Paeth-predictor function, named
after Alan W.~Paeth because it was first described by him in
\cite{arvo1994graphics_gems}. It is defined as is shown in
algorithm~\ref{alg:paeth}.


\begin{algorithm}[H]
  \caption{The Paeth-predictor.}
  \label{alg:paeth}
  \begin{algorithmic}[1]
    \Procedure{Paeth}{$a,b,c$}
    \Let{$\var{estimate}$}{$a+b-c$}
    \Let{$\Delta a$}{$|\var{estimate}-a|$}
    \Let{$\Delta b$}{$|\var{estimate}-b|$}
    \Let{$\Delta c$}{$|\var{estimate}-c|$}
    \linecomment{Return the delta closest to the estimate.}
    \If{$\Delta a \le \Delta b \AND \Delta a \le \Delta c $}
    \State \Return{$\Delta a$}
    \ElsIf{$\Delta b \le \Delta c$}
    \State \Return{$\Delta b$}
    \Else
    \State \Return{$\Delta c$}
    \EndIf
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\subsection{Scanline serialization}

\newcommand{\checkerimg}{
  \tikz[scale=2]{
    \fill[gray] (0,0) rectangle (0.5ex,0.5ex);
    \fill[black] (0.5ex,0) rectangle (1.0ex,0.5ex);
    \fill[black] (0,0.5ex) rectangle (0.5ex,1.0ex);
    \fill[gray] (0.5ex,0.5ex) rectangle (1.0ex,1.0ex);
  }}


Now let us describe the scanline serialization process. Say I have an
image with the size 2x2, meaning that it is two pixels wide and two
pixels high. This image uses indexed color with a color depth of 1 to
store the color. Let the index $0$ represent a fully black color and
the index $1$ represent gray color. Now let us that the first row of
this image consists of the color indexes $1$ and $0$ and that the
second consists of the indexes $0$ and $1$. Then this data would
represent the image \checkerimg. Then, after scanline serialization
process, the first row of this image will get encoded as a byte by
writing from the highest bits to the lowest, meaning that the
resulting byte will be $128$. The bit pattern for this number
\bin{\textbf{10}00\ 0000}. Separate rows in the image data are kept
separate from each other, so the second row will get encoded in a
separate byte value $64$(\bin{\textbf{01}00\ 0000}).

If on the other hand the color depth was 2, and the color values of
the indexes of the data were kept the same, $01$; $00$; $00$; $01$,
then the data would have been encoded as the bytes
$64$(\bin{\textbf{0100}\ 0000}) and $16$(\bin{\textbf{0001}\ 0000}).

Grayscale color is dealt with in very much the same way as indexed
color. The miscellaneous color types are often too big to fit in a
single byte, so the separate channel values are spread out over
consecutive bytes. If the channels sizes are over 8 bits, then also
the channels will get spread out over several bytes.

\subsection{Interlacing}
\label{png-interlacing}

The main idea behind \png interlacing is that the image to be
interlaced is divided into 8x8 tiles, and then the data of these tiles
are partitioned into $7$ distinct passes:

\[
\begin{matrix}
  1 & 6 & 4 & 6 & 2 & 6 & 4 & 6\\
  7 & 7 & 7 & 7 & 7 & 7 & 7 & 7\\
  5 & 6 & 5 & 6 & 5 & 6 & 5 & 6\\
  7 & 7 & 7 & 7 & 7 & 7 & 7 & 7\\
  3 & 6 & 4 & 6 & 3 & 6 & 4 & 6\\
  7 & 7 & 7 & 7 & 7 & 7 & 7 & 7\\
  5 & 6 & 5 & 6 & 5 & 6 & 5 & 6\\
  7 & 7 & 7 & 7 & 7 & 7 & 7 & 7\\
\end{matrix}
\]

This is best understood by using an example. Consider, for example, an
8-bit grayscale image that consisted of the grayscale data:

\[
\begin{matrix}
  1 & 2 & 3 & 4 & 5 & 6 & 7 & 8\\
  9 & 10 & 11 & 12 & 13 & 14 & 15 & 16\\
  17 & 18 & 19 & 20 & 21 & 22 & 23 & 24\\
  25 & 26 & 27 & 28 & 29 & 30 & 31 & 32\\
  33 & 34 & 35 & 36 & 37 & 38 & 39 & 40\\
  41 & 42 & 43 & 44 & 45 & 46 & 47 & 48\\
  49 & 50 & 51 & 52 & 53 & 54 & 55 & 56\\
  57 & 58 & 59 & 60 & 61 & 62 & 63 & 64\\

\end{matrix}
\]

The first pass of this interlaced image would consist of the 1x1 image
with a single color 1. Passes are treated like single images and these
single images will get scanline serialized separately. The images that
of the separate passes will then be found after each in the color
data. Pass would get scanline serialized to the byte $1$. It would
then followed by the 1x1 image that pass 2 also consists of. This
image consists of the color $5$ and so it will get serialized to
$5$. Pass 3 will on the other hand consist of the 2x1 image with the
single row $33,37$ and so on.

\begin{Exercise}[label={ex-interlace}]

  What would pass 5 consist of?

\end{Exercise}

To undo the interlacing first all the separate images that the passes
consists of will have to be read. Then the separate pixels must be
rearranged in proper order. It is shown in
algorithm~\ref{alg:png-interlace} how this is done.

\begin{algorithm}[H]
  \caption{Undoing the interlacing of the uncompressed \png color data}
  \label{alg:png-interlace}
  \begin{algorithmic}[1]
    \Let{$\var{startingRow}$}{$\{0, 0, 4, 0, 2, 0, 1\}$}
    \Let{$\var{startingCol}$}{$\{0, 4, 0, 2, 0, 1, 0\}$}
    \Let{$\var{rowIncrement}$}{$\{8, 8, 8, 4, 4, 2, 2\}$}
    \Let{$\var{colIncrement}$}{$\{8, 8, 4, 4, 2, 2, 1\}$}

    \Let{$i$}{$0$}

    \linecomment{In this algorithm, the pass numbers are zero based}
    \ForTo{$\var{pass}$}{$0$}{$7$}
    \Let{$\var{row}$}{$\var{startingRow[pass]}$}

    \While{$\var{row} < \var{imageHeight}$}

    \Let{$column$}{$\var{startingCol[pass]}$}

    \While{$\var{colmn} < \var{imageWidth}$}

    \Let{$j$}{$\var{row} \cdot \var{width} + \var{column}$}
    \Let{$\var{uninterlacedColorData[j]}$}{$\var{uncompressedColorData[i]}$}
    \Let{$i$}{$i + $}

    \Let{$\var{column}$}{$\var{column} + \var{colIncrement[pass]}$}

    \EndWhile

    \Let{$\var{row}$}{$\var{row} + \var{rowIncrement[pass]}$}

    \EndWhile

    \EndForTo

  \end{algorithmic}
\end{algorithm}



\section{Answers to the exercises}

\begin{Answer}[ref={filter-1}]

  \[
  \begin{matrix}
    1 & 2 & 1 & 1 & 1 \\
    1 & 4 & 5 & 5 & 5 \\
    1 & 2 & 10 & 247 & 17
  \end{matrix}
  \]

\end{Answer}

\begin{Answer}[ref={ex-interlace}]

  \[
  \begin{matrix}
    17 & 19 & 21 & 23 \\
    49 & 51 & 53 & 55
  \end{matrix}
  \]


\end{Answer}



