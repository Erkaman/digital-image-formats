\begin{comment}
  \bibliography{project.bib}
\end{comment}

\chapter{Run-Length Encoding}
\label{cha:rle}

In this chapter, we'll discuss the first compression algorithm of this
text. First, though, we will need to introduce the reader to some
terminology related to data compression, which is what the discussion
subject of the following section is going to be.

\section{Some Data Compression Terminology}

The following list of terminologies is based on the references
\cite{Salomon:2004:DCC,mark1996data_compression_book,Bell:1989:MTC:76894.76896}.

\subsection{Encoding, Decoding, Compression and Decompression}

Coding data into another form is referred to as
\textit{encoding}. Converting that encoded data back
to its original form is called \textit{decoding}.

In the circumstances of compression techniques, encoding and decoding
are also often referred to as \textit{compression}
and \textit{decompression}.

Compression could be described as the process of rewriting some data
on another form that is more space efficient and decompression is the
process that reveres the former process. How the data rewriting
process is performed is what the area of data compression is all
about.

In this text, we will only text treat lossless compression
algorithms. Data compressed losslessly can be restored to an identical
copy of the original data. In lossy compression on the other hand,
data is thrown away when necessary to make the compression even more
space efficient. It is for these reasons impossible to restore an
original copy of the data for data that has been lossily
compressed. It is however fully possible to restore losslessly
compressed data.

\subsection{Compression Ratio}

The compression ratio is a very useful
measure for when discussing the compression efficiency of a
compression algorithm. It is calculated like this:

\begin{equation*}
  {\rm Compression\;Ratio} = \frac{{\rm Compressed Size}}{{\rm Original Size}}
\end{equation*}

We will in this text specify the compression ratio in fractions or
percentages.

But it is important to realize that the compression ratio is
\textit{not} some constant number that can simply be assigned to a
compression algorithm. The compression ratio will always vary between
what kind file is to be compressed.

If for example some file originally contained the bytes $10,10,10$ and
after running some arbitrary compression algorithm on it it then
contained the bytes $3,10$, then the compression ratio of that
algorithm for this \textit{specific file} is $\frac{2}{3}$, which
basically means that $\frac{2}{3}$ of the original size was left
uncompressed by the algorithm, and that $\frac{1}{3}$ of the original
file size was saved by the compression.

\begin{Exercise}[label={compression-ratio}]

  Calculate the compression ratio for the following cases

  \begin{enumerate}[(a)]
  \item $12,13,14,15,16,17$ compressed down to $5,12$?
  \item $12,14,16,18,20,22$ compressed down to $5,12,2$?
  \item $12,12,12,13,45,45$ compressed down to $2,12,0,13,1,45$?
  \end{enumerate}

  Do note that different compression algorithms were used in all three
  cases. How was compression performed in the three cases?

\end{Exercise}

\section{RLE}
\label{sec:rle}

This following description of the RLE algorithm uses the references
\cite{nagarajan11:_enhan_approac_run_lengt_encod_schem,murray1996encyclopedia,mark1996data_compression_book}.

One the most simple compression algorithms is known as
\textit{Run-Length Encoding}, abbreviated
RLE. The compression performed in the third question of
exercise \ref{compression-ratio} is actually RLE compression.

In this algorithm, sequences of length $n$ of the same value $b$ are
compressed down to $(n-1,b)$. So the sequence $b,b,b,...,b$ of length
$n$ gets compressed down to $(n-1,b)$. The pairs that represents these
sequences of repeating values are known as \textit{packets}, and these
sequences of repeating values will from known on be known as
\textit{runs}. In our version of the RLE algorithm these runs are just
sequences of repeating bytes, and the two values in the packets $n-1$
and $b$ are for this reason stored in bytes.

But why is the length byte $n$ subtracted by $1$?  A byte can have
$256$ different values in the range $0-255$. But since it would be a
waste to have a packet of length $0$, the designers of the algorithm
decided that rather than letting the value zero go to waste, they
assigned the length value $0$ to $1$, $1$ to $2$ and so on. So while
the values stored in the packet are in the range $0-255$, they
actually represent range $1-256$, which has the added advantage that
the max length of a packet is $256$ rather than $255$.

But here's the main problem with this method: every single run of
values, even those for which $n=1$, are considered runs! So even a
single run of $b$ is represented by a packet $(0,b)$ and the algorithm
ends up doubling the size of the original data for such runs! More so,
if the data is just a string of runs for which $n=1$, then the
``compressed'' size of this data ends of up being the double value of
the original size. This means that strings like ``eric'' ends up
getting ``compressed'' down to ``0e0r0i0c'', and the compression ratio
of this compression is $\frac{2}{1} = 2$, which is an absolutely
horrible compression ratio.

And even for runs where $n=2$ this algorithm does no good. The run
$b,b$ is represented by the pair $(1,b)$, and while this at least
doesn't double the size of the data, no compression is performed in
this case either.

But for runs for which $n > 2$ we finally start seeing some
results. Then the run $b, b, \dots, b$ ends up simply being compressed
down to $(n-1,b)$, which results in a compression ratio of
$\frac{2}{n}$. The maximum value of $n$ is $256$, and thus the maximum
compression ratio of a single run is $\frac{2}{256} = \frac{1}{128}$,
which is a quite superb compression ratio!

So when data the contains a lot runs for which $n > 2$, then this
algorithm can indeed do great compression. English text is however not
one kind of data that is best compressed by RLE, since there are very
few English words where letters of repeated more than two times. True,
there does exist plenty of words with double consonants in the English
language, but, remember, RLE compression method does no compression
whatsoever for runs where $n=2$.

But there also examples of data that could be very efficiently
compressed by RLE. One example of this is grayscale data. The page on
which this text was printed on could be seen as many long runs of
grayscale data. So an image of this page is a good example of data
that could get quite efficient compression ratios using RLE.

\begin{Exercise}[label={rle-compression}]
  Using RLE, compress the following strings and also compute the
  compression ratio of the compression:

  \begin{enumerate}[(a)]
  \item AAABBBCCC
  \item eric
  \item success
  \end{enumerate}

\end{Exercise}

So for only certain kinds of data can RLE achieve efficient
compression, otherwise it is best avoided, since it could in worst
cases double the size of the data. We will in section ? discuss how
improve RLE by removing this limitation from the algorithm.

\subsection{The RLE Algorithm}

\subsubsection{RLE Compression Algorithm}

All of this is essentially trivial to implement in code. Let us first
consider the compression algorithm, which is shown in algorithm
\ref{alg:rle-enc}. What follows is the explanation of this algorithm.

\begin{algorithm}
  \caption{Encoding a file using RLE.}
  \label{alg:rle-enc}
  \begin{algorithmic}[1]

    \Let{$\var{length}$}{$0$}
    \Let{$c_1$}{ \VoidCall{ReadByte}}

    \While{\True}

    \Let{$c_2$}{ \VoidCall{ReadByte}}

    \If{\eof}
    \Break
    \EndIf

    \If{$c_1 = c_2 \AND \var{length} < 255$}
    \Let{$\var{length}$}{$1 + \var{length}$}
    \Else
    \linecomment{Write the packet}
    \State \Call{WriteByte}{$\var{length}$}
    \State \Call{WriteByte}{$c_1$}

    \Let{$c_1$}{$c_2$}
    \Let{$\var{length}$}{$1$}
    \EndIf

    \EndWhile

    \linecomment{Write the last packet.}
    \State \Call{WriteByte}{$\var{length}$}
    \State \Call{WriteByte}{$c_1$}
  \end{algorithmic}
\end{algorithm}

First we read the first character in the file to the variable
$c_1$. Then the following character is read to $c_2$, but if the file
only consisted of the character now stored in $c_1$, then we stop and
just write out a packet $(1,c_1)$.

Else, the two most recently read characters are compared for equality,
and if they are equal we have found a run where $n > 1$. However, we
may just as this comparison is done already be in the process of
making a packet and so we need to check for the current packet if $n <
255$. This is necessary because $n$ is stored in a byte and values $>
255$ can't fit in a byte.

If $c_1$ and $c_2$ were not equal or $n = 255$, we now need to write
out the current packet $(n,c_1)$. Now $c_1$ is set to $c_2$, so that
we may begin processing the next packet.

You could also see the algorithm like this: The character that is to
be repeated by the packet is read to $c_1$. To find the length of the
packet, characters are repeatedly read to $c_2$, which are then
compared to $c_1$. If $c_1 \neq c_2$, then we have found the end of
the run, and so the packet is outputted. Then a new character to be
repeated is read into $c_1$ and the process starts anew.

And in a loop this algorithm is repeated until all the characters of
the file have been processed. Once we have processed all the
characters in the file, we also need to write out the last packet at
the end of the algorithm.

\subsubsection{RLE Decompression Algorithm}

\begin{algorithm}
  \caption{Decoding a RLE encoded file.}
  \label{alg:rle-dec}
  \begin{algorithmic}[1]

    \Let{$\var{length}$}{\VoidCall{ReadByte}}
    \Let{$c$}{\VoidCall{ReadByte}}

    \While{\neof}
    \Repeatn{$\var{length} + 1$}
    \State \Call{WriteByte}{$b$}
    \EndRepeatn

    \Let{$\var{length}$}{\VoidCall{ReadByte}}
    \Let{$c$}{\VoidCall{ReadByte}}

    \EndWhile
  \end{algorithmic}
\end{algorithm}

The ridiculously simple RLE decoding algorithm is shown in algorithm
\ref{alg:rle-dec}.

It is very simple: pairs of $(n-1,b)$ are read in pair by pair. These
pairs are then expanded to sequences $b,b,\dots,b$ of length $n$ and
written to the output file. This process is repeated pair by pair
until we have reached to the end the input file.

\section{PackBits RLE}
\label{sec:packbits-rle}

The information in the following section is based on the sources
\cite{96:_techn_note_tn102,apple1994inside,91:_truev_tga_file_format_specif}

The algorithm that we are about to describe is in
\cite{96:_techn_note_tn102,apple1994inside} known as the PackBits
method. But in \cite{91:_truev_tga_file_format_specif}, however, this
algorithm is simply known as RLE. I will therefore try and create a
compromise between these two names and we therefore will call the
method PackBits RLE from now on.

As familiar, the RLE algorithm can do great compression on certain
kind of data, while it on the other can double the size of other kinds
of data, like English text. The question is, can we remove this
limitation from the algorithm, while still preserving its great
compression ratio for certain kinds of data?

And yes, it turns out that we can. In PackBits RLE, the highest bit of
the packet length specifier for a packet $(n-1,b)$, is reserved not
for specifying the length of the packet, but for specifying the
\textit{type} of the packet.

Since only one bit is used for specifying the type of a packet, there
can only be two types of packet, and these two types are: Run-length
packets and raw packets. If the packet is a raw packet, then the
highest bit of $n$ is cleared and if it is a run-length packet then
the bit is toggled.

These two packets differ in what kind of data they contain. The
run-length packet contains run-length encoded, compressed,
data. Run-length packets are used in exactly the same way as they are
in plain RLE.

To give an example, the data $5,5,5$, will in PackBits RLE get
compressed down to ``130,5''. This makes sense because $130$ in binary
is $1000\ 0010$. The highest bit is here used to specify that the
packet is a run-length packet and the 7 lowest bits are used to
specify the actual length of the packet.

Because only 7 bits are used to specify the length of a run-length
packet, the maximum length of a run-length packet in PackBits RLE is
$2^7 = 128$.

But in exchange for a potentially lowered compression ratio, we did
get something in return: raw packets. Raw packets essentially is the
fix to the problem of potentially doubling the size of ``compressed''
files that plain RLE had.

What the $n$ value in raw packets specify, is the length of a
following sequence of raw data. This packet type could in other words
be used to store strings that RLE can't really compress, like the data
$1,2,3,4$ for example. In PackBits RLE, the string $1,2,3,4$ would
most efficiently get encoded as $3,1,2,3,4$. $3$ is in binary form
$0000\ 0011$, and the since the highest bit is cleared, this means
that this is a proper raw packet.

Because PackBits RLE now lacks the ability to explode the size of the
data in the way plain RLE can, the main advantage PackBits RLE has
over plain RLE is that it is a lot more \textit{reliable}.

\begin{Exercise}[label={packbits-rle}]

  Compress the following data using the PackBits RLE method, and
  calculate the compression ratio:

  \begin{enumerate}[(a)]
  \item success
  \item AAABBBCCC
  \item Suddenly he shouted AAAAAAAAA
  \end{enumerate}

\end{Exercise}

\subsection{Algorithm}

\subsubsection{Writing The Packets}

Let us first consider how to write a raw packet. This is shown in
algorithm \ref{alg:raw-packet}). This function simply writes out the
length of the packet, which is followed by all the data of the raw
packet,

\begin{algorithm}
  \caption{Writing a raw packet.}
  \label{alg:raw-packet}
  \begin{algorithmic}[1]
    \Function{writeRawPacket}{$\var{length,data}$}
    \State \Call{writeByte}{$\var{length}$}
    \ForEach{$\var{raw}$}{$\var{data}$}
    \State \Call{writeByte}{$\var{raw}$}
    \EndForEach
    \EndFunction
  \end{algorithmic}
\end{algorithm}

In algorithm \ref{alg:rle-packet} it is shown how to write a
run-length packet. To make sure that the highest bit is toggled, the
length bit is assigned to an initial value of $1 \ShiftLeft 7 =
128$. The length is then added to the length byte by bitwise oring the
7 lower bits with the actual length of the packet subtracted by 1.

\begin{algorithm}
  \caption{Writing a run length packet.}
  \label{alg:rle-packet}
  \begin{algorithmic}[1]
    \Require $\var{length} > 0$
    \Function{writeRunLengthPacket}{$\var{length,data}$}
    \Let{packetHead}{$128$}
    \Let{packetHead}{$\var{packetHead} \BitOr \var{length}$}
    \State \Call{writeByte}{$\var{packetHead}$}
    \State \Call{writeByte}{$\var{data}$}
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\subsubsection{Compression And Decompression}
\label{sec:compr-decompr}

Now that we know how to write the packets, let us consider how to
implement the actual PackBits RLE algorithm. It is shown in algorithm
\ref{alg:packbits-enc}.

Since there are two kinds of packets allowed in the PackBits RLE
method, we will need a way of telling which kind of packet we are
creating at the time. The two constants $\var{RawPacket}$ and
$\var{RunLengthPacket}$ are created for this purpose. The values of these
two constants are then assigned to the variable $\var{packetType}$ for
keeping track of the current packet type.

We start the algorithm by setting up a starting packet of length 1 of
type raw packet. The first character of the file is then read to $c_1$
and following this the second character in the file is read to
$c_2$. However, if there's only one character in the file, then the
main loop is stopped and the last packet is written. Since we were
dealing with a raw packet the only character $c_1$ is put in the array
$\var{data}$. The array $\var{data}$ stores the data of the current
raw packet.

If there however was more than one character, then it is first checked
if the current packet is at its maximum capacity. If so, then the
current packet is written out. If the current packet is a run-length
packet then the run-length packet is simply written out and
preparations are made for writing a new raw packet. If the packet is a
raw packet then the character $c_1$ is put at the end of the $\var{data}$
array, and then the raw packet is written out. The next character is
read to $c_2$, which is why we beforehand assigns $c_1$ to $c_2$ after
we have written the raw packet, to ensure that the value of $c_2$ is
not destroyed.

If on the other hand the current packet is not full then we are going
to write a run-length packet. First however, we need to check if we
are not already writing a raw packet. If so, then we finish the raw
packet by outputting it. Then the construction of the run-length
packet continues by incrementing the $\var{length}$ variable and setting the
current packet type to run length packet.

If the current packet is not full and $c_1 \neq c_2$, then we are
writing are raw packet. If we were also writing a run length packet at
this time then we finish it by outputting it.

And when the loop is over, the last, remaining packet is finished and
outputted.

\begin{algorithm}
  \caption{Encoding a file using PackBits RLE.}
  \label{alg:packbits-enc}
  \begin{algorithmic}[1]
    \Let{$\var{RawPacket}$}{$0$}
    \Let{$\var{RunLengthPacket}$}{$1$}
    \Let{$\var{packetType}$}{$\var{RawPacket}$}
    \Let{$\var{length}$}{$0$}
    \Let{$c_1$}{ \VoidCall{ReadByte}}

    \While{\neof}

      \Let{$c_2$}{ \VoidCall{ReadByte}}

      \If{\eof}
        \Break
      \EndIf
      \linecomment{If the current packet is full.}
      \If{$\var{length} = 127$}

        \If{$\var{packetType} = \var{RunLengthPacket}$}

         \State \Call{writeRunLengthPacket}{$\var{length},c_1$}
         \Let{$\var{packetType}$}{$\var{RawPacket}$}
         \Let{$\var{length}$}{$0$}

       \ElsIf{$\var{packetType} = \var{RawPacket}$}

         \Let{$\var{data[length]}$}{$c_1$}
         \State \Call{writeRawPacket}{$\var{length},\var{data},\var{out}$}
         \Let{$\var{length}$}{$0$}
         \Let{$c_1$}{$c_2$}

      \EndIf
    \ElsIf{$c_2 = c_1$}

      \linecomment{Finish the current raw packet, if necessary}
      \If{$\var{packetType} = \var{RawPacket} \AND \var{length} > 0$}
        \State \Call{writeRawPacket}{$\var{length}-1,\var{data},\var{out}$}
        \Let{$\var{length}$}{$0$}
      \EndIf

      \Let{$\var{length}$}{$1 + \var{length}$}
      \Let{$\var{packetType}$}{$\var{RunLengthPacket}$}

    \Else

      \If{$\var{packetType} = \var{RunLengthPacket}$}

        \State \Call{writeRunLengthPacket}{$\var{length},c_1$}
       \Let{$\var{packetType}$}{$\var{RawPacket}$}
       \Let{$\var{length}$}{$0$}

      \ElsIf{$\var{packetType} = \var{RawPacket}$}

        \Let{$\var{data[length]}$}{$c_1$}
        \Let{$\var{length}$}{$\var{length} + 1$}

      \EndIf

       \Let{$c_1$}{$c_2$}

    \EndIf

    \EndWhile

    \If{$\var{packetType} = \var{RunLengthPacket}$}
      \State \Call{$writeRunLengthPacket$}{$\var{length},c_1$}
    \Else
      \Let{$\var{data[length]}$}{$c_1$}
    \State \Call{$writeRawLengthPacket$}{$\var{length},\var{data}$}
    \EndIf
  \end{algorithmic}
\end{algorithm}

The decoding algorithm is thankfully not as complex. It is shown in
algorithm \ref{alg:packbits-dec}.

\begin{algorithm}
  \caption{Decoding a RLE packbits encoded file.}
  \label{alg:packbits-dec}
  \begin{algorithmic}[1]

    \Let{$\var{packet}$}{\VoidCall{ReadByte}}

    \While{\neof}

      \Let{$\var{length}$}{$\var{packet} \BitAnd 127$}

      \linecomment{Check if raw packet.}
      \If{$\var{packet} \BitAnd 128$}
        \Let{$\var{data}$}{\VoidCall{ReadByte}}

        \Repeatn{$\var{length} + 1$}
        \State \Call{WriteByte}{$\var{data}$}
        \EndRepeatn
      \Else

        \Repeatn{$\var{length} + 1$}
        \Let{$\var{data}$}{\VoidCall{ReadByte}}
        \State \Call{WriteByte}{$\var{data}$}
        \EndRepeatn

      \EndIf

      \Let{$\var{packet}$}{\VoidCall{ReadByte}}

    \EndWhile
  \end{algorithmic}
\end{algorithm}

\FloatBarrier

\answers{}

\begin{Answer}[ref={compression-ratio}]

  \begin{enumerate}[(a)]
  \item $\frac{1}{3}$

    The data is just a sequential list of numbers and the difference
    between all the numbers is $1$. This sequence can be compressed
    down to a pair $(n,s)$, where $s$ is the starting value and $n$ is
    the length of the sequence. This pair can then be decompressed
    like this: $s,s+1,s+2,\cdots,s+n$.

  \item $\frac{1}{2}$

    We are once again dealing with a sequential list of numbers, but
    in this case the difference between them is $2$. If we assign the
    symbol $\Delta$ to this difference, then sequence

    \begin{equation*}
      s, s + 1 \cdot \Delta, s + 2 \cdot \Delta, \dots, s + n \cdot \Delta
    \end{equation*}

    can be represented by the triplet $(n,s,\Delta)$

  \item $\frac{6}{6} = 1$.

    The compression ratio is $1$, meaning that no compression
    whatsoever ended up being performed in the long run.

    This data was compressed using the RLE algorithm, and we will
    discuss this algorithm in section \ref{sec:rle}.

  \end{enumerate}
\end{Answer}

\begin{Answer}[ref={rle-compression}]

  \begin{enumerate}[(a)]
  \item 2A2B2C, $\frac{2}{3}$
  \item 0e0r0i0c, $2$
  \item 0s0u1c0e1s, $\frac{10}{7}$
  \end{enumerate}

\end{Answer}

\begin{Answer}[ref={packbits-rle}]

  \begin{enumerate}[(a)]
  \item 6success, $\frac{8}{7}$
  \item 130A130B130C, $\frac{2}{3}$
  \item 18Suddenly he shouted136A, $\frac{22}{29}$
  \end{enumerate}

\end{Answer}

