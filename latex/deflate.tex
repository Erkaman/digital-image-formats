\begin{comment}
  \bibliography{project.bib}
\end{comment}

\chapter{Deflate}
\label{cha:deflate}

We will in this chapter discuss the \deflate algorithm based on the
references
\cite{pkware:_appnot,deutsch96:_deflat_compr_data_format_specif,Salomon:2004:DCC,feldspar:_explan_deflat_algor}

\section{History}

The \deflate algorithm was devised by Phil Katz for usage in the Zip
format he had also invented and it was first formally defined in
\cite{deutsch96:_deflat_compr_data_format_specif}. The algorithm
itself uses a combination of \lzone and Huffman coding.

\section{Length and Distance Codes}

\deflate compressed data has a prespecified format. But before we can
describe that format, we first need a good view of the algorithm
operates to begin with.

\deflate compressed data on the basic level consists of two kinds of
data: literal bytes and length-distance pairs. This means that it uses
a \lzone variation to do compression. It uses a system very similar to
that of lzss, as we will soon see.

An alphabet of 0--255 is used to encode literal bytes, which are just
like unmatched tokens; that is, tokens for which for no match was
found for in the \lzone window. The special value $256$ is used to
indicate the end of the compressed data. Note that this value is part
of the \textit{same} alphabet as the literal bytes. Also part of the
same alphabet are the length codes. They can be found in the range
257--285, and they are used to indicate the length of the \lzone matched
strings. All these values forms an alphabet of values 0--285. This
entire alphabet will also get Huffman coded in the later parts of the
algorithm.

The length codes are a bit tricky to use, though. Please observe table
\ref{tab:deflate-length-codes}. This table means that if a code of
$257$ is found then that means that this code in reality represents a
length of $3$, and in the same way a code of $262$ represents a length
of $8$. But how should a code like $265$ be parsed? First, we will
remark that the minimum length this code can represent is $11$. This
code is then followed by a single extra bit, as indicated by the
table. The value of the extra bit is added to minimum code length to
get the true code length represented by the previous code. In other
words, a code of $265$ followed by the extra bit $1$ will represent
the code length $12$, but had it on the other hand been followed by
the single bit $0$, then it would have represented the code length
$11$. In the same way, a length of $95$ is indicated by the length
code $278$ followed by the 4-bit number $\bin{1100}=12$.

\begin{table}

  \newcommand*\hdr{Code &  \parbox[t]{5mm}{Extra\\bits} & Lengths}
  \begin{minipage}[t]{0.32\textwidth}
    \centering
    \begin{tabular}{lll}
      \toprule
      \hdr{} \\
      \midrule
      257 & 0 & 3 \\
      258 & 0 & 4 \\
      259 & 0 & 5 \\
      260 & 0 & 6\\
      261 & 0 & 7 \\
      262 & 0 & 8 \\
      263 & 0 & 9 \\
      264 & 0 & 10 \\
      265 & 1 & 11--12 \\
      266 & 1 & 13--14 \\
      \bottomrule
    \end{tabular}
  \end{minipage}
  \begin{minipage}[t]{0.32\textwidth}
    \centering
    \begin{tabular}{lll}
      \toprule
      \hdr{} \\
      \midrule
      267 & 1 & 15--16 \\
      268 & 1 & 17--18 \\
      269 & 2 & 19--22 \\
      270 & 2 & 23--26\\
      271 & 2 & 27--30 \\
      272 & 2 & 31--34 \\
      273 & 3 & 33--42 \\
      274 & 3 & 43--50 \\
      275 & 3 & 51--58 \\
      276 & 3 & 59--66 \\
      \bottomrule
    \end{tabular}
  \end{minipage}
  \begin{minipage}[t]{0.32\textwidth}
    \centering
    \begin{tabular}{lll}
      \toprule
      \hdr{} \\
      \midrule
      277 & 4 & 67-82 \\
      278 & 4 & 83-98 \\
      279 & 4 & 99-114 \\
      280 & 4 & 115-130\\
      281 & 5 & 131-162 \\
      282 & 5 & 163-194 \\
      283 & 5 & 195-226 \\
      284 & 5 & 227-257 \\
      285 & 0 & 258 \\
      % dirty hack, but it works.
      & & \\
      \bottomrule
    \end{tabular}
  \end{minipage}

  \caption{\deflate length codes}
  \label{tab:deflate-length-codes}
\end{table}

Following a length code and its accompanying extra bits is always a
distance code. By the way, offsets are termed distances in the \deflate
literature. The distance codes are drawn from the alphabet 0--29 and
they are stored in very much the same way as length codes, as is shown
in table \ref{tab:deflate-distance-codes}. So a distance of $30000$
will be represented by a distance code 29 followed by the 13-bit value
5423, since

\begin{equation*}
  24577 + 5423 = 30000
\end{equation*}

Length distance codes form pair to represent strings that have been
matched for in the window. First comes the length code and its extra
bits, and after the distance code and its extra bits. If no matches
could be made, then literal bytes are simply used.

\begin{table}

  \newcommand*\hdr{Code &  \parbox[t]{5mm}{Extra\\bits} & Distances}
  \begin{minipage}[t]{0.32\textwidth}
    \centering
    \begin{tabular}{lll}
      \toprule
      \hdr{} \\
      \midrule
      0 & 0 & 1 \\
      1 & 0 & 2 \\
      2 & 0 & 3 \\
      3 & 0 & 4\\
      4 & 1 & 5--6\\
      5 & 1 & 7--8 \\
      6 & 2 & 9--12 \\
      7 & 2 & 13--16 \\
      8 & 3 & 17--24 \\
      9 & 3 & 25--32 \\
      \bottomrule
    \end{tabular}
  \end{minipage}
  \begin{minipage}[t]{0.32\textwidth}
    \centering
    \begin{tabular}{lll}
      \toprule
      \hdr{} \\
      \midrule
      10 & 4 & 33--48 \\
      11 & 4 & 49--64 \\
      12 & 5 & 65--96 \\
      13 & 5 & 97--128 \\
      14 & 6 & 129--192 \\
      15 & 6 & 193--256 \\
      16 & 7 & 257--384 \\
      17 & 7 & 385--512 \\
      18 & 8 & 512--768 \\
      19 & 8 & 769--1024 \\
      \bottomrule
    \end{tabular}
  \end{minipage}
  \begin{minipage}[t]{0.32\textwidth}
    \centering
    \begin{tabular}{lll}
      \toprule
      \hdr{} \\
      \midrule
      20 & 9 & 1025--1536  \\
      21 & 9 & 1537--2048  \\
      22 & 10 & 2049--3072  \\
      23 & 10 & 3073--4096  \\
      24 & 11 & 4097--6144  \\
      25 & 11 & 6145--8192  \\
      26 & 12 & 8193--12288  \\
      27 & 12 & 12289--16384  \\
      28 & 13 & 17385--24576  \\
      29 & 13 & 24577--32768  \\
      \bottomrule
    \end{tabular}
  \end{minipage}

  \caption{\deflate distance codes}
  \label{tab:deflate-distance-codes}
\end{table}

\section{Fixed Huffman Codes}
\label{sec:fixed-huffman-codes}

All the codes in the distance/literal and length alphabets will be
encoded in the compressed data using Huffman codes. But the Huffman
tree must also be passed along with the data for it to be decompressed
properly. There are two sorts of ways of doing this: fixed and dynamic
Huffman codes. Let us first discuss the most of simple of these two:
fixed Huffman codes.

Using fixed Huffman codes the Huffman codes of the both alphabets are
precomputed(it is shown in section ? \todo{reference section} how
these Huffman codes are computed). The precomputed Huffman codes for
the first alphabet are shown in table
\ref{tab:fixed-length-litteral-huffman}. Using this table, the end
code, 256, will be represented by the 7-bit Huffman Code
\bin{0000000}, the literal code 142 will on the other hand be
represented by the 8-bit Huffman code \bin{10111110} and the length
code 258 will be represented by the 7-bit Huffman code
\bin{0000010}. The reader may however be confused by the inclusion of
the two length codes 286 and 287. Did not the literal/length alphabet
only span the range 0--285? The two codes 286 and 287 will according
to the \deflate specification never be found in the compressed data. So
it is to us incomprehensible why these two codes are given assigned
Huffman codes. But since they will never occur in the data we can
safely ignore them. The Huffman encoded length codes will obviously,
if there are any, also be followed by their accompanying extra bits.

The fixed Huffman Distance codes are on the other hand represented in
a more simple way: Distance codes 0-29 are assigned 5-bit Huffman
codes of their corresponding values, meaning that, for example, the
distance code of 28 will be represented by a 5-bit number with the
value 28. And of course, these distance codes encoded as Huffman codes
will be followed by their accompanying extra bits.

\begin{table}
  \centering
  \begin{tabular}{lll}
    \toprule
    Codes & Bits & Huffman Codes \\
    \midrule
    0--143 & 8 & \bin{00110000}--\bin{10111111} \\
    144--255 & 9 & \bin{110010000}--\bin{111111111} \\
    256--279 & 7 & \bin{0000000}--\bin{0010111} \\
    280--287 & 8 & \bin{11000000}--\bin{11000111} \\
    \bottomrule
  \end{tabular}
  \caption{Fixed Huffman codes for the first alphabet}
  \label{tab:fixed-length-litteral-huffman}
\end{table}

\section{Dynamic Huffman Codes}
\label{sec:dynamic-huffman-codes}

\subsection{Computing the Huffman Tree}

The Huffman codes can also be computed in the \deflate algorithm. Using
dynamic Huffman codes the token will be assigned Huffman codes that
are, in most cases, more space efficent than those of the fixed
Huffman codes. For very short this may however make little different
in space savings, and dynamic Huffman codes tend not be used for small
files for these reasons. But for larger files dynamic Huffman will in
general pay off.

These Huffman code are actually computed in a very peculiar way, and
this is what we will be discussing for the rest of this section. As should
familiar from chapter \ref{cha:huffman}, the computed Huffman is
rarely unique, but many different Huffman tree can be computed. In
chapter \ref{cha:huffman} we constructed a Huffman tree for the string
$\var{ababaacdd}$ and ended up with the Huffman tree:

\begin{huffmanc}
  \node[hnode] {9}
  child {node[hnode]{5}
    child{node[hnode]{3}
      child{node(cnode)[hnode] {1}}
      child{node(bnode)[hnode] {2}}}
    child{node (dnode) [hnode] {2}}}
  child{node (anode) [hnode] {4}};

  \nodechar{cnode}{c}
  \nodechar{bnode}{b}
  \nodechar{dnode}{d}
  \nodechar{anode}{a}
\end{huffmanc}

But as was shown in exercise \ref{nuther}, this Huffman tree was not
by any means unique. However, if add the following requirements to the
construction of the Huffman tree it is guaranteed to be unique:

\begin{enumerate}
\item Shorter codes will always be to right in the Huffman tree, while
  longer codes will always be found on the left.
\item And for codes of the same length, these codes are sorted by
  lexographic order, meaning that they are sorted by order of the
  alphabet, so letters that are lexographically shorter be always be
  placed on the left.
\end{enumerate}

Placing these requirements on the former tree, the only possible
Huffman tree for the string $\var{ababaacdd}$ will be

\begin{huffmanc}
  \node[hnode] {9}
  child{node (anode) [hnode] {4}}
  child{node[hnode]{5}
    child{node (dnode) [hnode] {2}}
    child{node[hnode]{3}
      child{node(bnode)[hnode] {2}}
      child{node(cnode)[hnode] {1}}
    }};

  \nodechar{cnode}{c}
  \nodechar{bnode}{b}
  \nodechar{dnode}{d}
  \nodechar{anode}{a}
\end{huffmanc}

\begin{table}
  \centering
  \begin{tabular}{ll}
    \toprule
    Letter & Code \\
    \midrule
    $a$ & $0$ \\
    $b$ & $110$ \\
    $c$ & $111$ \\
    $d$ & $10$ \\
    \bottomrule
  \end{tabular}
  \caption{Sorted Huffman Codes}
  \label{tab:huffman-codes-sorted}
\end{table}

The letters we then be assigned the codes shown in table
\ref{tab:huffman-codes-sorted}. This tree will always be unique,
because it is sorted by the only two properties that a code can have:
its length and the symbol it represents.

But one very important thing that most literature on \deflate often
omits is exactly how this sorted Huffman tree is made, and this
what well spend the rest of this section explaining.

The algorithm used by the most \deflate implementation is the
following: first, a non-unique and unsorted Huffman tree is built

\begin{huffmanc}
  \node[hnode] {9}
  child {node[hnode]{5}
    child{node[hnode]{3}
      child{node(cnode)[hnode] {1}}
      child{node(bnode)[hnode] {2}}}
    child{node (dnode) [hnode] {2}}}
  child{node (anode) [hnode] {4}};

  \nodechar{cnode}{c}
  \nodechar{bnode}{b}
  \nodechar{dnode}{d}
  \nodechar{anode}{a}
\end{huffmanc}

Note that this tree can really be any if the possible Huffman trees that can
be constructed from the input.

\subsection{Representing the Huffman Tree}

Now, how is now the Huffman tree passed along with the compressed
tokens? It turns out that it is actually fully possible to represent
the sorted Huffman by the code lengths of the codes represented by the
tree, assuming that these codes are sorted in the lexicographic order
by the symbols which they are supposed to represent. From the input
string $\var{ababaacdd}$ the sorted Huffman codes shown in table
\ref{tab:huffman-codes-sorted} are shown. We will now show that is
fully possible to represent these codes by the respective code lengths
in lexicographical order:

\begin{equation*}
  1,3,3,2
\end{equation*}

What follows is the algorithm to convert the code lengths to sorted
Huffman codes:

\begin{enumerate}
\item The frequencies of the code lengths are put into an array that
  is often called $\var{blCount}$ in the \deflate literature. For our
  example, $\var{blCount[1]} = 1$, $\var{blCount[2]} = 1$ and
  $\var{blCount[3]} = 2$.

\item The numerical value of the smallest code for each code length is then
  found. Once these values have been computed most of the job in
  computing the codes is done. Because since the codes of the same
  code lengths we be sorted in lexographic order, the difference
  between single codes in the same code lengths groups will always be
  one. The most leftmost code in a code length will have the minimum
  code length computed in this step, and the code to the left of this
  group, assuming that it has the same length, will have a code with a
  value $+1$ the previous code length.

  However, computing these smallest codes values for each code lengths
  turns out to be more easily said than done. But we take several
  things into consideration, we will see that this is not very
  difficult. First of all, the smallest value of each the first group
  of code lengths will always be $0$. This follows from the fact that
  codes of smaller code lengths will always be placed leftmost in the
  tree. Since left branches represents cleared bits($0$), the minimum
  value of that smallest code lengths will be $0$. This fact can also
  be easily interpreted from our example tree:

\begin{huffmanc}
  \node[hnode] {9}
  child{node (anode) [hnode] {4}}
  child{node[hnode]{5}
    child{node (dnode) [hnode] {2}}
    child{node[hnode]{3}
      child{node(bnode)[hnode] {2}}
      child{node(cnode)[hnode] {1}}
    }};

  \nodechar{cnode}{c}
  \nodechar{bnode}{b}
  \nodechar{dnode}{d}
  \nodechar{anode}{a}
\end{huffmanc}

\todo{now explain why the addition and shifting step makes sense.}

  \begin{algorithm}[H]
    \caption{Finding the smallest code of each code length}\algohack{}    \label{alg:smallest-code-length}
    \begin{algorithmic}[1]
      \Let{$\var{code}$}{0}
      \linecomment{The minimum value of the smallest code length group
      be always be $0$}
      \Let{$\var{blCount[0]}$}{0}
      \linecomment{(Every bit from 1 $MAXBITS$ is counted,$MAXBITS+1$
        is not included)}
      \ForTo{$\var{bits}$}{1}{$\var{MAXBITS+1}$}
        \Let{$\var{code}$}{$(\var{code} + \var{blCount[bits-1]})
          \ShiftLeft 1$}
        \Let{$\var{minCodes[bits]}$}{$\var{code}$}
      \EndForTo
    \end{algorithmic}
  \end{algorithm}

  \item Now that we have computed the minimum values of each code
    length, we can very easily compute the rest of the codes. This is
    simply done be assigning the increasing values of the minimum code
    lengths to our code length groups. To compute the code for $c$,
    $110 + 001 = 111$ is computed; this is the value following the
    minimum code value for that code length group, since $c$ is found
    directly next to the value to the leftmost, $b$, in its group.

\end{enumerate}

And one last thing: to signify that a symbol will not get assigned a
code at all, meaning that it is not used in the data at all, it is
assigned a code length of $0$. If for example only ASCII letters are
used in our compressed data, then all the control character will be
assigned code lengths of $0$. So there will be a long sequence of
zeroes in the beginning of the code length sequence, since the code
length of \textit{every} character has to be included for the proper
codes to be computed; the computer cannot be expected to guess that
some codes are not at all assigned, it has to be indicated of this
exlicitly. However, this also has the unfortunate consequence that the
sequence of code lengths would in the beginning just be a long
sequence of zeroes, and this is not particulary space efficent
considering how redundant such a sequence would be. These code lengths
are this reason compressed in the \deflate algorithm, which is the
something we will discuss in the next section.

\section{Storing the Huffman Codes}
\label{sec:storing-huffman-codes}

Now let us discuss how the code length compression is done. First we
will remind the reader that the maximum length of a code from any of
the two alphabets(literal/length- and distance alphabets) must be
less than 16. So the range values reqired to encode the code lengths
of both the alphabets is 0--15. For compressing the \textit{code
  lengths of the Huffman codes} of two alphabets another alphabet
named the code length alphabet is introduced. This alphabet will
\textit{also} get Huffman coded, but we will get to that later.

Codes 0--15 are in this alphabet used to specify simple,
noncompressed code lengths.

A code of 16 is used the specify that the previous code is to be
repeated a number of times. Following this is code is always a 2-bit
number indicating the repetition count. Do note that while a 2-bit
number specifies the range 0--2, this number is in fact used to specify
the range 3--6. This is because repetions in the former range makes
little to sense out a compression performance perspective, because a
run of two identical code lengths is specified just as well with two
unencoded code lengths than a single code followed by the code 16 and
its 2-bit repetition specifier.

So to indicate a run of 11 repeated code lengths of $3$, the following
codes would be used.

\begin{equation*}
  3, 16, \bin{11}, 16, \bin{00}
\end{equation*}

This will indicate a run of $1 + 6 + 4 = 11$ repeated codes with the
value $3$.

Long runs of zero are however very common in the sequences of code
lengths and the former code is not particularly good at specifying
very long runs. For this purpose the codes $17$ and $18$ were
invented. Codes of $17$ will be followed by 3-bit numbers for
indicating runs of zero, and \textit{only} zero, with lengths in the
range 3--10. In the same way, $18$ will be followed a 7-bit numbers
for specifying runs of zero in the with lengths in the range 11--138.

Using the code lengths alphabet the two former alphabets can be
represented much more succinctly. The code lengths of the alphabets
are obviously sorted before they are compressed and stored. So the
code length for ``a'' will always come before the code length for
``b''. But introducing this alphabet the question yet again comes up:
how do we represent this new alphabet as efficiently as possible?

The alphabet of code lengths will first of all be Huffman coded. The
frequencies of the codes are gathered from the compressed data of the
code lengths of the two former alphabets. Only the codes are used in
the computation of the Huffman codes, \textit{not the repetition
  specifiers}, as is wrongly indicated by \cite{Salomon:2004:DCC}. The
Huffman codes will be stored as code lengths in 3-bit numbers, meaning
that the maximum length of a code from this alphabet will be $2^3 - 1
= 7$.

We are almost done now. The last thing we need to discuss is how the
code lengths for the Huffman codes of the code lengths alphabet are
stored, because in this case it is done in a very peculiar way.

The alphabet for the code lengths is 0--18. The code lengths are not
however stored in this order. Rather, they are permuted in the
following order:

\begin{equation*}
  16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15
\end{equation*}

This for example means that the code length of code $16$ will be
stored first. The rationale for this is that the lengths at the end
are much more likelier to be zero in this permutation. Left out values
will be defaulted to zero, meaning that they will get left out of the
code construction process. If there are trailing zeroes then these
zeroes can be left out, since they will be defaulted to zero anyways,
saving some space.

And this permutation makes sense out of that perspective; the codes
for specifying repetitions, $16$, $17$, $18$, will often be used in
compressing code lengths, since runs of zero tend to be very
common. This is because it is for most kinds of data very unusual that
all possible values in a byte, 0--255, are even used in the data. For
example, most ASCII control characters will often never occur in
English language texts, resulting in long runs of zero.

And the permutation being ended by values such as $1$ and $15$ and
$14$ sort of also makes sense. It is very unusual for Huffman trees to
reach sizes so big that code lengths of $15$ and $14$ are even used or
necessary. They will for this reason often be left out, and therefore
be set to $0$. Small trees are also rather unusual and therefore code
sizes of $1$ and $2$ will also be rarely used. Typically, most Huffman
trees are averagely sized; neither to big nor to small.

\section{The Deflate format}

\subsection{The header bits}

Now we are finally ready to discuss the \deflate format. \deflate
compressed data is structured into \textit{blocks}. Every block begins
with a 3-bit header(the three \textit{lowest} bits of the first byte
are used). These 3 bits are used to specify how the data is compressed
in the block.

\subsubsection{BFINAL(1 bit(0,the lowest one))}

\deflate compressed data will consist of a sequence of compressed
blocks. The uncompressed data of all blocks will when concatenated
together form the original data. This bit is used to specify whether
this block is the final block in the file, meaning that it is used to
indicate the of the compressed data. If it is the toggled bit, $1$,
that means that the end of the blocks has been reached; otherwise,
there are more blocks following this block.

\subsubsection{BTYPE(2 bits(1--2))}

This values is used to indicate the compression type used in the
block, and therefore decides the format of the current block. It can
have $2^2 = 4$ different kinds of values, but since the value \bin{11}
is reserved, unsused, there are reality only three possible ways of
the compressing the data in a block. What types of compression the
three possible values of this field indicates is what we will be
discussing for the rest of this chapter.

\subsection{Non-compressed block (BTYPE=00)}

The most simple way of storing the data in a block is by simply not
compressing it at all, which is what is done by this block type. The
rest of the remaining 5 bits of the header byte are ignored, and
following this are the following values:

\subsubsection{LEN(2 bytes)}

This value is used to specify the length of the non-compressed block.

\subsubsection{NLEN(2 bytes)}

This field is basically useless and we will not discuss it.

\subsubsection{Non-compressed, literal Data(bytes)}

This contains a sequence of non-compressed byte data. Obviously, the
length of this sequence is the value of the LEN field.

While the non-compressed block-type may seem useless, it does have
several usages. It can for example store sections of data in a file
which is inflated by compression. As we saw in chapter \ref{cha:rle},
it is fully possible for a compression algorithm to explode the size
of the compressed data. But for \deflate, this is something that most
typically happens for very random data. Data in which there are close
to redundancies at all. So to summarize, this block can be useful for
storing parts of a file that contains \textit{very} random data.

\subsection{Compression with fixed Huffman codes (BTYPE=01))}

The data in the block is compressed using the fixed, precomputed,
Huffman codes we discussed in section
\ref{sec:fixed-huffman-codes}. So the compressed data will in other
words just contain a sequence of Huffman codes for the two
alphabets. The 5 remaining bits of the header byte of the block will
be used for storing Huffman codes, so they are not skipped in this
case.

\subsection{Compression with dynamic Huffman codes (BTYPE=11))}

In the last block type dynamic Huffman codes are instead computed. We
already discussed in depth how this is done in section
\ref{sec:dynamic-huffman-codes}, so we will not delve to deep into
details here.

\subsection{HLIT (5 bits)}

These bits are used to specify the number of code lengths used to
encode the literal/length code alphabet. The number of code lengths
from this alphabet will actually be $\var{HLIT} + 257$ and the max
value of this sum $286$, and \textit{not} $288$, because this is the
number specified by the \deflate specification. By specifying different
values if $\var{HLIT}$ you can leave out trailing zeroes in the code
length data, increasing compression a bit. But you cannot of course
leave out non-zero code lengths, because these actually used in
computing the Huffman codes.

\subsection{HDIST (5 bits)}

In the same way, the code lengths of the distance alphabet is
specified as the sum $\var{HDIST} + 1$. The allowed range for this sum
is 1--32.

\todo{discuss edgecases where only one or no codes at all are used
  from this alphabet.}

\subsection{HCLEN (4 bits)}

The number of code lengths from the code lengths alphabet is specified
by the sum $\var{HCLEN} + 4$, in the range 4--19.

\subsection{Code Length Alphabet Code Lengths}

And finally, here comes the code lengths for the alphabet of code
lengths, permuted in the order we discussed in section
\ref{sec:storing-huffman-codes}. The code lengths of this alphabet
were limited to 7 bits of length, meaning that these code lengths are
stored using 3-bit numbers; more specifically, the length of this
sequence will be $(\var{HCLEN} + 4) \cdot 3$ bits.

\subsection{Literal/Length Alphabet Code Lengths}

The literal/length alphabet is here encoded using the Huffman Codes
from the unencoded code lengths codes. $\var{HLIT} + 257$ code lengths
will, as familiar, be found in this sequence.

\subsection{Distance Alphabet Code Lengths}

And in the exact same way, the $\var{HDIST} + 1$ code lengths for the
distances codes are stored here.
