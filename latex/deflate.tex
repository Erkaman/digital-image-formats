\begin{comment}
  \bibliography{project.bib}
\end{comment}

\chapter{Deflate}
\label{cha:deflate}

We will in this chapter discuss the \deflate algorithm based on the
references
\cite{pkware:_appnot,deutsch96:_deflat_compr_data_format_specif,Salomon:2004:DCC,feldspar:_explan_deflat_algor}

\section{History}

The \deflate algorithm was devised by Phil Katz for usage in the Zip
format he had also invented and it was first formally defined in
\cite{deutsch96:_deflat_compr_data_format_specif}. The algorithm
itself uses a combination of \lzone and Huffman coding.

\section{Length and Distance Codes}

\deflate compressed data has a prespecified format. But before we can
describe that format, we first need a good view of how the algorithm
operates.

\deflate compressed data on the basic level consists of two kinds of
data: literal bytes and length-distance pairs. This means that it uses
a \lzone variation to do compression. It uses a system very similar to
that of \lzss, as we will soon see.

An alphabet of 0--255 is used to encode literal bytes, which are just
like unmatched tokens; that is, tokens indicating that no matches were
found in the \lzone window. The special value $256$ is used to
indicate the end of the compressed data. Note that this value is part
of the \textit{same} alphabet as the literal bytes. Also part of the
same alphabet are the length codes. They can be found in the range
257--285, and they are used to indicate the length of the \lzone
matched strings. All these codes forms an alphabet of 0--285. This
entire alphabet will also get Huffman coded.

The length codes are a bit tricky to use, though. Their usage is
specified in table.  table~\ref{tab:deflate-length-codes}. This table
means that a code of $257$ represents a length of $3$, and in the same
way a code of $262$ represents a length of $8$. But how should a code
like $265$ be parsed? First, we will remark that the minimum length
this code can represent is $11$. This code is then followed by a
single extra bit, as indicated by the table. The value of the extra
bit is added to minimum code length to get the true code length
represented by the previous code. In other words, a code of $265$
followed by the extra bit $1$ will represent the code length $12$, but
had it on the other hand been followed by the single bit $0$, then it
would have represented the code length $11$. In the same way, a length
of $95$ is indicated by the length code $278$ followed by the 4-bit
number $\bin{1100}=12$, since

\begin{equation*}
  83 + 12 = 95
\end{equation*}

\begin{table}
  \footnotesize
  \newcommand*\hdr{Code &  \parbox[t]{5mm}{Extra\\bits} & Lengths}
  \begin{minipage}[t]{0.32\textwidth}
    \centering
    \begin{tabular}{lll}
      \toprule
      \hdr{} \\
      \midrule
      257 & 0 & 3 \\
      258 & 0 & 4 \\
      259 & 0 & 5 \\
      260 & 0 & 6\\
      261 & 0 & 7 \\
      262 & 0 & 8 \\
      263 & 0 & 9 \\
      264 & 0 & 10 \\
      265 & 1 & 11--12 \\
      266 & 1 & 13--14 \\
      \bottomrule
    \end{tabular}
  \end{minipage}
  \begin{minipage}[t]{0.32\textwidth}
    \centering
    \begin{tabular}{lll}
      \toprule
      \hdr{} \\
      \midrule
      267 & 1 & 15--16 \\
      268 & 1 & 17--18 \\
      269 & 2 & 19--22 \\
      270 & 2 & 23--26\\
      271 & 2 & 27--30 \\
      272 & 2 & 31--34 \\
      273 & 3 & 33--42 \\
      274 & 3 & 43--50 \\
      275 & 3 & 51--58 \\
      276 & 3 & 59--66 \\
      \bottomrule
    \end{tabular}
  \end{minipage}
  \begin{minipage}[t]{0.32\textwidth}
    \centering
    \begin{tabular}{lll}
      \toprule
      \hdr{} \\
      \midrule
      277 & 4 & 67-82 \\
      278 & 4 & 83-98 \\
      279 & 4 & 99-114 \\
      280 & 4 & 115-130\\
      281 & 5 & 131-162 \\
      282 & 5 & 163-194 \\
      283 & 5 & 195-226 \\
      284 & 5 & 227-257 \\
      285 & 0 & 258 \\
      % dirty hack, but it works.
      & & \\
      \bottomrule
    \end{tabular}
  \end{minipage}

  \caption{\deflate length codes}
  \label{tab:deflate-length-codes}
\end{table}

Following a length code and its accompanying extra bits is always a
distance code. By the way, offsets are termed distances in the \deflate
literature. The distance codes are drawn from the alphabet 0--29 and
they are stored in very much the same way as length codes, as is shown
in table~\ref{tab:deflate-distance-codes}. So a distance of $30000$
will be represented by a distance code 29 followed by the 13-bit value
5423, since

\begin{equation*}
  24577 + 5423 = 30000
\end{equation*}

Length and distance codes form pairs to represent strings that have
been matched for in the window. First comes the length code and its
extra bits, and after that the distance code and its extra bits. If no
matches could be made, then literal bytes are simply used.

\begin{table}
  \footnotesize
  \newcommand*\hdr{Code &  \parbox[t]{5mm}{Extra\\bits} & Distances}
  \begin{minipage}[t]{0.32\textwidth}
    \centering
    \begin{tabular}{lll}
      \toprule
      \hdr{} \\
      \midrule
      0 & 0 & 1 \\
      1 & 0 & 2 \\
      2 & 0 & 3 \\
      3 & 0 & 4\\
      4 & 1 & 5--6\\
      5 & 1 & 7--8 \\
      6 & 2 & 9--12 \\
      7 & 2 & 13--16 \\
      8 & 3 & 17--24 \\
      9 & 3 & 25--32 \\
      \bottomrule
    \end{tabular}
  \end{minipage}
  \begin{minipage}[t]{0.32\textwidth}
    \centering
    \begin{tabular}{lll}
      \toprule
      \hdr{} \\
      \midrule
      10 & 4 & 33--48 \\
      11 & 4 & 49--64 \\
      12 & 5 & 65--96 \\
      13 & 5 & 97--128 \\
      14 & 6 & 129--192 \\
      15 & 6 & 193--256 \\
      16 & 7 & 257--384 \\
      17 & 7 & 385--512 \\
      18 & 8 & 512--768 \\
      19 & 8 & 769--1024 \\
      \bottomrule
    \end{tabular}
  \end{minipage}
  \begin{minipage}[t]{0.32\textwidth}
    \centering
    \begin{tabular}{lll}
      \toprule
      \hdr{} \\
      \midrule
      20 & 9 & 1025--1536  \\
      21 & 9 & 1537--2048  \\
      22 & 10 & 2049--3072  \\
      23 & 10 & 3073--4096  \\
      24 & 11 & 4097--6144  \\
      25 & 11 & 6145--8192  \\
      26 & 12 & 8193--12288  \\
      27 & 12 & 12289--16384  \\
      28 & 13 & 17385--24576  \\
      29 & 13 & 24577--32768  \\
      \bottomrule
    \end{tabular}
  \end{minipage}

  \caption{\deflate distance codes}
  \label{tab:deflate-distance-codes}
\end{table}

\section{Fixed Huffman Codes}
\label{sec:fixed-huffman-codes}

All the codes in the literal/literal and distance alphabets will be
encoded in the compressed data using Huffman codes. But the Huffman
tree must also be passed along with the data for it to be decompressed
properly. There are two sorts of ways of doing this: fixed and dynamic
Huffman codes. Let us first discuss the most of simple of these two:
fixed Huffman codes.

Using fixed Huffman codes, the Huffman codes of the both alphabets are
precomputed. The precomputed Huffman codes for the first alphabet are
shown in table~\ref{tab:fixed-length-litteral-huffman}. So the end
code, 256, will be represented by the 7-bit Huffman code
\bin{0000000}, the literal code 142 will on the other hand be
represented by the 8-bit Huffman code \bin{10111110} and the length
code 258 will be represented by the 7-bit Huffman code
\bin{0000010}. The reader may however be confused by the inclusion of
the two length codes 286 and 287. Did not the literal/length alphabet
only span the range 0--285?  The two codes 286 and 287 will according
to the \deflate specification never be found in the compressed
data. So it is to us incomprehensible why these two codes are even
given Huffman codes. But since they will never occur in the data we
can safely ignore them. The Huffman encoded length codes will
obviously, if there are any, also be followed by their accompanying
extra bits.

The fixed Huffman Distance codes are on the other hand represented in
a more simple way: Distance codes 0-29 are assigned 5-bit Huffman
codes of their corresponding values, meaning that, for example, the
distance code of 28 will be represented by a 5-bit number with the
value 28. And of course, these distance codes encoded as Huffman codes
will be followed by their accompanying extra bits.

\begin{table}
  \centering
  \begin{tabular}{lll}
    \toprule
    Codes & Bits & Huffman Codes \\
    \midrule
    0--143 & 8 & \bin{00110000}--\bin{10111111} \\
    144--255 & 9 & \bin{110010000}--\bin{111111111} \\
    256--279 & 7 & \bin{0000000}--\bin{0010111} \\
    280--287 & 8 & \bin{11000000}--\bin{11000111} \\
    \bottomrule
  \end{tabular}
  \caption{Fixed Huffman codes for the first alphabet}
  \label{tab:fixed-length-litteral-huffman}
\end{table}

\section{Dynamic Huffman Codes}
\label{sec:dynamic-huffman-codes}

\subsection{Sorted Huffman Trees}

The Huffman codes can also be computed from the input data. Using
dynamic Huffman codes, the codes will be assigned Huffman codes that
are, in a majority of cases, more space efficient than those of the
fixed Huffman codes. For very small input data this may however make
very little difference in space savings, and since the dynamic Huffman
codes have to be passed along with the compressed data, dynamic
Huffman codes tend to not be used at all for small files. But for
larger files dynamic Huffman codes will in general pay off.

As should be familiar from chapter~\ref{cha:huffman}, the constructed
Huffman tree is rarely unique, but many different Huffman trees can be
made. In chapter~\ref{cha:huffman} we constructed a Huffman tree for
the string \texttt{ababaacdd} as

\begin{huffmanc}
  \node[hnode] {9}
  child {node[hnode]{5}
    child{node[hnode]{3}
      child{node(cnode)[hnode] {1}}
      child{node(bnode)[hnode] {2}}}
    child{node (dnode) [hnode] {2}}}
  child{node (anode) [hnode] {4}};

  \nodechar{cnode}{c}
  \nodechar{bnode}{b}
  \nodechar{dnode}{d}
  \nodechar{anode}{a}
\end{huffmanc}

But as was shown in exercise~\ref{nuther}, this Huffman tree was not
by any means unique. However, if we add the following requirements to
the construction of the Huffman tree it is guaranteed to be unique:

\begin{enumerate}
\item Shorter codes will always be found to the left in the Huffman
  tree, while longer codes will always be found to the right.
\item And for codes of the same length, these codes are sorted by
  lexicographic order, meaning that they are sorted by the order of the
  alphabet, so letters that are lexicographically shorter be always be
  placed on the left.
\end{enumerate}

Such a tree will always be unique, because it is sorted by the only
two properties that a code can have: its length and the symbol it
represents.

Placing these requirements on the former tree, the only possible
Huffman tree for the string \texttt{ababaacdd} will be

\begin{huffmanc}
  \node[hnode] {9}
  child{node (anode) [hnode] {4}}
  child{node[hnode]{5}
    child{node (dnode) [hnode] {2}}
    child{node[hnode]{3}
      child{node(bnode)[hnode] {2}}
      child{node(cnode)[hnode] {1}}
    }};

  \nodechar{cnode}{c}
  \nodechar{bnode}{b}
  \nodechar{dnode}{d}
  \nodechar{anode}{a}
\end{huffmanc}

\begin{table}
  \centering
  \begin{tabular}{ll}
    \toprule
    Letter & Code \\
    \midrule
    \texttt{a} & $0$ \\
    \texttt{b} & $110$ \\
    \texttt{c} & $111$ \\
    \texttt{d} & $10$ \\
    \bottomrule
  \end{tabular}
  \caption{Sorted Huffman Codes}
  \label{tab:huffman-codes-sorted}
\end{table}

And as we can easily see, this tree fulfills all the above
requirements; all the shorter codes are placed to the left in the
tree, and the codes of the same length are sorted
lexicographically. The sorted Huffman codes from this tree are shown
in table~\ref{tab:huffman-codes-sorted}.

% But one very important thing that most literature on \deflate often
% omits is exactly how this sorted Huffman tree is made, and this
% what well spend the rest of this section explaining.

% The algorithm used by the most \deflate implementation is the
% following: first, a non-unique and unsorted Huffman tree is built

% \begin{huffmanc}
%   \node[hnode] {9}
%   child {node[hnode]{5}
%     child{node[hnode]{3}
%       child{node(cnode)[hnode] {1}}
%       child{node(bnode)[hnode] {2}}}
%     child{node (dnode) [hnode] {2}}}
%   child{node (anode) [hnode] {4}};

%   \nodechar{cnode}{c}
%   \nodechar{bnode}{b}
%   \nodechar{dnode}{d}
%   \nodechar{anode}{a}
% \end{huffmanc}

% Note that this tree can really be any if the possible Huffman trees that can
% be constructed from the input.

\subsection{Representing the Huffman Tree}

Now, how is now the Huffman tree passed along with the
tokens(represented by literal/length pairs)? It turns out that it is
fully possible to represent the sorted Huffman tree by the code
lengths of the codes represented by the tree, assuming that these
codes are sorted in the lexicographic order by the symbols which they
are supposed to represent. From the input string \texttt{ababaacdd}
the sorted Huffman codes shown in table~\ref{tab:huffman-codes-sorted}
were computed. We will now show that is fully possible to represent
these codes by their respective code lengths in lexicographical order:

\begin{equation*}
  1,3,3,2
\end{equation*}

What follows is the algorithm to convert the code lengths to sorted
Huffman codes:

\begin{enumerate}
\item The frequencies of the code lengths are put into an array that
  is often called $\var{blCount}$ in the \deflate literature. For our
  example, $\var{blCount[1]} = 1$, $\var{blCount[2]} = 1$ and
  $\var{blCount[3]} = 2$.

\item The value of the smallest code for each code length is then
  computed. Once these values have been computed, most of the job in
  computing the codes is done. The leftmost code in a code length will
  have the minimum code value computed in this step.

  The minimum code length of the smallest code length will always be
  $0$. This follows from the fact that codes of smaller code lengths
  will always be placed leftmost in the tree and from the fact that
  left branches represents cleared bits($0$). This fact can also be
  easily interfered from our example tree:

\begin{huffmanc}
  \node[hnode] {9}
  child{node (anode) [hnode] {4}}
  child{node[hnode]{5}
    child{node (dnode) [hnode] {2}}
    child{node[hnode]{3}
      child{node(bnode)[hnode] {2}}
      child{node(cnode)[hnode] {1}}
    }};

  \nodechar{cnode}{c}
  \nodechar{bnode}{b}
  \nodechar{dnode}{d}
  \nodechar{anode}{a}
\end{huffmanc}

Now, how will the minimum values of the following code lengths be
computed? They will be computed as the sum of the former code length
frequency and the former minimum code bitwise left shifted by one
step. This is shown in algorithm \ref{alg:smallest-code-length}. For
our example, $\var{minCodes[1]} = 0$, because the first minimum value
will always be 0. $\var{minCodes[2]}$ will on the other hand be
computed as

  \begin{equation*}
    (0 + \var{blCount[2]}) \ShiftLeft 1 = (0 + 1)
    \ShiftLeft 1 = \bin{10}
  \end{equation*}

  And similarly,

  \begin{equation*}
    \var{minCodes[3]} =  (\bin{10} + \var{blCount[2]}) \ShiftLeft 1 =
      (\bin{10} + \bin{01}) \ShiftLeft 1 = \bin{110}
  \end{equation*}

  \begin{algorithm}[H]
    \caption{Finding the smallest code of each code length}\algohack{}    \label{alg:smallest-code-length}
    \begin{algorithmic}[1]
      \Let{$\var{code}$}{0} \linecomment{The minimum value of the
        smallest code length be always be $0$}
      \Let{$\var{blCount[0]}$}{0}

      \Let{$\var{bits}$}{1}
      \While{$\var{bits} \le {MAXBITS}$}
        \Let{$\var{code}$}{$(\var{code} + \var{blCount[bits-1]})
          \ShiftLeft 1$}
        \Let{$\var{minCodes[bits]}$}{$\var{code}$}

        \Let{$\var{bits}$}{$\var{bits} + 1$}
      \EndWhile
    \end{algorithmic}
  \end{algorithm}

\item Now that we have computed the minimum values of each code
  length, we can very easily compute the rest of the codes. This is
  simply done by assigning the increasing values of the minimum code
  lengths to the codes with the same length. The code of \texttt{c} is
  computed as $110 + 001 = 111$; this is the value following the
  minimum code value for that code length, since \texttt{c} is found
  directly next to the value to the minimum code, \texttt{b}.

\end{enumerate}

And one last thing: to signify that a symbol will not get assigned a
code at all, meaning that it is not used in the data at all, it is
assigned a code length of $0$. If for example only \ascii letters are
used in our compressed data, then all the control character will be
assigned code lengths of $0$. So there will be a long sequence of
zeroes in the beginning of the code length sequence, since the code
length of \textit{every} character has to be included for the proper
codes to be computed; the computer cannot be expected to guess that
some codes are not at all assigned, it has to be indicated of this
explicitly. However, this also has the unfortunate consequence that
the sequence of code lengths would in the beginning just be a long
sequence of zeroes, and this is not particularly space efficient
considering how redundant such a sequence would be. These code lengths
are for this reason compressed in the \deflate algorithm, which is the
something we will discuss in the next section.

\section{Storing the Huffman Codes}
\label{sec:storing-huffman-codes}

Now let us discuss how the code length compression is done. The
maximum code length from any of the two alphabets is by Deflate
specification required to be 16. This makes sure that the code lengths
can be encoded using a simple alphabet 0--15. For compressing the
\textit{code lengths of the Huffman codes} of two alphabets another
alphabet named the code length alphabet is introduced. This alphabet
will \textit{also} get Huffman coded, but we will get to that later.

Codes 0--15 are in this alphabet used to specify simple,
non-compressed code lengths.

A code of 16 is used the specify that the previous code is to be
repeated a number of times. Following this is code is always a 2-bit
number indicating the repetition count. Do note that while a 2-bit
number specifies the range 0--2, this number is in fact used to specify
the range 3--6. This is because repetitions in the former range makes
little to sense out a compression performance perspective, because a
run of two identical code lengths is specified just as well with two
unencoded code lengths than a single code followed by the code 16 and
its 2-bit repetition specifier.

So to indicate a run of 11 repeated code lengths of $3$, the following
codes would be used.

\begin{equation*}
  3, 16, \bin{11}, 16, \bin{00}
\end{equation*}

This will indicate a run of $1 + 6 + 4 = 11$ repeated codes with the
value $3$.

Long runs of zero are however very common in the sequences of code
lengths and the former code is not particularly good at specifying
very long runs. For this purpose the codes $17$ and $18$ are
used. Codes of $17$ will be followed by 3-bit numbers for indicating
runs of zero, and \textit{only} zero, with lengths in the range
3--10. In the same way, $18$ will be followed a 7-bit numbers for
specifying runs of zero with lengths in the range 11--138.

Using the code lengths alphabet the two former alphabets can be
represented much more succinctly. The code lengths of the alphabets
are obviously sorted before they are compressed and stored. So the
code length for ``a'' will always come before the code length for
``b''. But introducing this alphabet the question yet again comes up:
how do we represent this new alphabet as efficiently as possible?

The alphabet of code lengths will first of all be Huffman coded. The
frequencies of the codes are gathered from the compressed data of the
code lengths of the two former alphabets. Only the codes are used in
the computation of the Huffman codes, \textit{not the repetition
  specifiers}, as is wrongly indicated by \cite{Salomon:2004:DCC}. The
Huffman codes will be stored as code lengths in 3-bit numbers, meaning
that the maximum length of a code from this alphabet will be $2^3 - 1
= 7$.

We are almost done now. The last thing we need to discuss is how the
code lengths for the Huffman codes of the code lengths alphabet are
stored, because in this case it is done in a very peculiar way.

The alphabet for the code lengths is 0--18. The code lengths are not
however stored in this order. Rather, they are permuted in the
following order:

\begin{equation*}
  16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15
\end{equation*}

This means that the code length of code $16$ will be stored first. The
rationale for this is that the lengths at the end are much more
likelier to be zero in this permutation. These can be left out, since
left out values will be defaulted to zero in \deflate.

And this permutation makes sense out of that perspective; the codes
for specifying repetitions, $16$, $17$, $18$, will often be used in
compressing code lengths, since runs of zero tend to be very
common. This is because it is for most kinds of data very unusual that
all possible values in a byte, 0--255, are even used in the data. For
example, most \ascii control characters will often never occur in
English language texts, resulting in long runs of zero.

And the permutation being ended by values such as $1$ and $15$ and
$14$ sort of also makes sense. It is very unusual for Huffman trees to
reach sizes so big that code lengths of $15$ and $14$ are even used or
necessary. They will for this reason often be left out, and therefore
be set to $0$. Small trees are also rather unusual and therefore code
sizes of $1$ and $2$ will also be rarely used. Typically, most Huffman
trees are averagely sized; neither to big nor to small.

\section{The Deflate format}

\subsection{The header bits}

Now we are finally ready to discuss the \deflate format. \deflate
compressed data is structured into \textit{blocks}. Every block begins
with a 3-bit header(the three \textit{lowest} bits of the first byte
are used). These 3 bits are used to specify how the data is compressed
in the block.

\subsubsection{BFINAL(1 bit(0,the lowest one))}

\deflate compressed data will consist of a sequence of compressed
blocks. The uncompressed data of all blocks will when concatenated
together form the original data. This bit is used to specify whether
this block is the final block in the file, meaning that it is used to
indicate the of the compressed data. If it is the toggled bit, $1$,
that means that the end of the blocks has been reached; otherwise,
there are more blocks following this block.

\subsubsection{BTYPE(2 bits(1--2))}

This values is used to indicate the compression type used in the
block, and therefore decides the format of the current block. It can
have $2^2 = 4$ different kinds of values, but since the value \bin{11}
is reserved, unsused, there are reality only three possible ways of
the compressing the data in a block.

\subsection{Non-compressed block (BTYPE=00)}

The most simple way of storing the data in a block is by simply not
compressing it at all, which is what is done by this block type. The
rest of the remaining 5 bits of the header byte are ignored, and
following this are the following values:

\subsubsection{LEN(2 bytes)}

This value is used to specify the length of the non-compressed block.

\subsubsection{NLEN(2 bytes)}

This field is basically useless and we will not discuss it.

\subsubsection{Non-compressed, literal Data(bytes)}

This contains a sequence of non-compressed byte data. Obviously, the
length of this sequence is the value of the LEN field.

While the non-compressed block-type may seem useless, it does have
several usages. It can for example store sections of data in a file
which is inflated by compression. As we saw in chapter~\ref{cha:rle},
with \rle, it is fully possible for a compression algorithm to explode
the size of the compressed data. But for \deflate, this is something
that most typically happens for very random data; data in which there
are close to redundancies at all.

\subsection{Fixed Huffman Codes (BTYPE=01))}

The data in the block is compressed using the fixed, precomputed,
Huffman codes we discussed in
section~\ref{sec:fixed-huffman-codes}. So the compressed data will in
other words just contain a sequence of Huffman codes for the two
alphabets. The 5 remaining bits of the header byte of the block will
be used for storing the Huffman codes of the compressed data, so they
are not skipped in this case.

\subsection{Dynamic Huffman Codes (BTYPE=11))}

In the last block type dynamic Huffman codes are instead computed. We
already discussed in depth how this is done in
section~\ref{sec:dynamic-huffman-codes}.

\subsection{HLIT (5 bits)}

These bits are used to specify the number of code lengths used to
encode the literal/length code alphabet. The number of code lengths
from this alphabet will actually be $\var{HLIT} + 257$ and the max
value of this sum $286$, and \textit{not} $288$, because this is the
number specified by the \deflate specification. By specifying different
values if $\var{HLIT}$ you can leave out trailing zeroes in the code
length data, increasing compression a bit. But you cannot of course
leave out non-zero code lengths, because these actually used in
computing the Huffman codes.

\subsection{HDIST (5 bits)}

In the same way, the code lengths of the distance alphabet is
specified as the sum $\var{HDIST} + 1$. The allowed range for this sum
is 1--32.

\subsection{HCLEN (4 bits)}

The number of code lengths from the code lengths alphabet is specified
by the sum $\var{HCLEN} + 4$, in the range 4--19.

\subsection{Code Length Alphabet Code Lengths}

And finally, here comes the code lengths for the alphabet of code
lengths, permuted in the order we discussed in
section~\ref{sec:storing-huffman-codes}. The code lengths of this
alphabet were limited to 7 bits of length, meaning that these code
lengths are stored using 3-bit numbers; more specifically, the length
of this sequence will be $(\var{HCLEN} + 4) \cdot 3$ bits.

\subsection{Literal/Length Alphabet Code Lengths}

The literal/length alphabet is here encoded using the Huffman Codes
from the decoded code lengths codes. $\var{HLIT} + 257$ code lengths
will, as familiar, be found in this sequence.

\subsection{Distance Alphabet Code Lengths}

And in the exact same way, the $\var{HDIST} + 1$ code lengths for the
distances codes are stored here.
