\begin{comment}
  \bibliography{project.bib}
\end{comment}

\chapter{Compression techniques}
\label{cha:compress-techn}

\begin{refsection}

\section{Some terminology}
\label{sec:some-terminology}

\subsection{Encoding and decoding}
\label{sec:encoding-decoding}

Coding data into another form is often referred to as
\textbf{encoding}\index{encoding}. Converting that encoded data back
to its original form is called
\textbf{decoding}\index{decoding}. \todo{Need sources on these two
  terms.} In the circumstances of compression techniques, encoding and
decoding are also often referred to as
\textbf{compression}\index{compression} and
\textbf{decompression}\index{decompression}.

\subsection{Compression ratio}
\label{sec:compression-ratio}

The compression ratio\index{compression ratio} is a very useful concept when talking about a
compression algorithms efficiency. The compression ratio of an
algorithm is calculated like this:

\begin{equation}
  \label{eq:compress-ratio}
  {\rm Compression\;Ratio} = \frac{\rm Compressed\;Size}{\rm Uncompressed\;Size}
\end{equation}

So the compression ratio basically tells how much data was
compressed. Of course, the lower compression ratio the better. But
there are ratios to take in heed, like performance and complexity of
the algorithm, but we will ignore these concepts in this book to book
to keep things simple. We will for the rest of the book specify the
compression ratio in percentages, $\%$\cite{Salomon:2004:DCC}.

% http://www.digitizationguidelines.gov/term.php?term=encoder

\section{Pseudocode conventions}
\label{sec:pseud-conv}

In this chapter, we'll actually start covering some algorithms. We
will describe these using pseudocode. The pseudocode will try to kept
as traditional as possible, but we'll still need to establish some
conventions for it:

\subsection{Boolean operators}
\label{sec:boolean-operators}

For signifying the boolean operators we'll be using the following
symbols:

\begin{description}
\item[$\NOT$] logical \textit{not}
\item[$\AND$] logical \textit{and}
\item[$\OR$] logical \textit{or}
\end{description}

\subsection{Bitwise operators}
\label{sec:bitwise-operators}

\newcommand{\C}{\textsc{C}}

We will for example also use the bitwise operators. If you
haven't even heard of them, look up them and study them on your own. I
assumed from the beginning of this book that such knowledge should be
obvious to you. We will be using the notation used in \C{} to
represent them in pseudocode:

% looks ugly when typeset.
\begin{description}
\item[$\BitNeg$] Bitwise \textit{NOT}
\item[$\BitAnd$] Bitwise \textit{AND}
\item[$\BitOr$] Bitwise \textit{OR}
\item[$\BitXor$] Bitwise \textit{XOR}
\item[$\ShiftLeft$] Left bit shift
\item[$\ShiftRight$] Right bit shift
\end{description}

Notice that we are using $\BitXor$ for typesetting bitwise
\textit{XOR} rather than the traditional \C{} notation. This is due to
the fact that we'd otherwise confuse it with logical and, $\AND$.

\subsection{Pseudocode Functions}
\label{sec:pseudocode}

We'll be dealing with files in these compression algorithms. Do not
forget that these algorithms could of course the implemented  using
ordinary array or lists. So we'll need to introduce several functions
for dealing with files:

\begin{description}
\item[\textproc{ReadByte}] It is assumed from the beginning of the
  algorithm that a file has already been opened for reading. This
  could be the file we're either trying to compress or
  decompress. This function reads a byte from that file.

\item[\textproc{WriteByte}] At the beginning of every algorithm, we also
  assume that there is a file opened for output. This function writes
  a byte to that file.

\item[\textproc{EndOfFileReached}] \True{} if the end the file we're
  reading from have been reached.

\end{description}

Although we will be dealing in bytes in these algorithms, they could
easily by generalized to compression or decompressing other integer
types likes \texttt{long} or \texttt{short}.

\subsection{Other conventions}
\label{sec:other-conventions}

We will also a be using a custom control structure \algorithmicrepeat,
which is demonstrated in algorithm \ref{alg:repeat}.

\begin{algorithm}[h]
  \caption{The repeat control structure.}
  \label{alg:repeat}
  \begin{algorithmic}[1]
    \Repeat{$n$}
      \State $actions\ldots$ \Comment{Repeats $actions\ldots n$ times} %
    \EndRepeat
  \end{algorithmic}
\end{algorithm}

The start of a comment is specified by the symbol \commentsymbol.

\section{Run Length Encoding}
\label{sec:rle}

\subsection{Naive version}
\label{sec:most-simple-version}

One the most simple compression algorithms is known as \textit{Run
  Length Encoding}\index{Run Length Encoding}(abbreviated
RLE\index{RLE})\cite{nagarajan11:_enhan_approac_run_lengt_encod_schem}.
The algorithm works like this: Sequences of consecutive data are stored
in packets containing a data count and a single value, rather than the
entire run of data.

But what does that actually \textit{mean}? Let us consider the string

\begin{indentpar}
  WWWWAAAACCCCCCQ
\end{indentpar}

As we can see, there are several runs of duplicated data in this
string. What if we instead of storing all of the duplicated data,
stored a number that tells how many times the following character
is replicated. And that's the RLE algorithm in a nutshell.

So when running the RLE encoding algorithm on this string, it is
compressed like this:

\newcommand{\pkt}[2]{\textbf{#1}#2}

\begin{indentpar}
  \pkt{4}{W}\pkt{4}{A}\pkt{6}{C}\pkt{1}{Q}
\end{indentpar}

So all the RLE encoding algorithm really does is encode long
consecutive runs of the same value as a count and a single data
value. We from now on will call a sequence of a data count and the
data itself a \textit{packet}\index{packet}.

But however, the same thing is also done for single runs, meaning that
the algorithm can potentially explode the size of the original data
rather than compress it. Consider,for example, the string

\begin{indentpar}
  eric
\end{indentpar}

this will actually get ``compressed'' down to

\newcommand{\spkt}[1]{\pkt{1}{#1}}

\begin{indentpar}
  \spkt{e}\spkt{r}\spkt{i}\spkt{c}
\end{indentpar}

So the size actually doubled for this kind of data! So for very data
with very varying values, like photos and books, this algorithm will
do just horrible. But in data in which the values are not varied much
at all, like that robot logo we showed in the last chapter, even for such a
naive algorithm, it will do quite good. In table \ref{tab:rle-comp} the compression
ratio of the algorithm for some sample data is demonstrated. As can be
seen from the table, the comrpession algorithm is a single value that
can be assgined to an algorithm, but it depents on the kind of data
that is being compressed. Some data may yield a high compression ratio
for a simple algorithm, while data may potentially explode it.

\begin{table}[h!]
  \centering
  \begin{tabular}[h!]{llr}
    \toprule
    Uncompressed data & compressed data & compression ratio($\%$) \\
    \midrule
    AAAEEERR & \pkt{3}{A}\pkt{3}{E}\pkt{2}{R} & $75$ \\
    ericarne & \spkt{e}\spkt{r}\spkt{i}\spkt{c}\spkt{a}\spkt{r}\spkt{n}\spkt{e} & $200$ \\
    BBBWWWBBBWWWBBBWWW & \pkt{3}{B}\pkt{3}{W}\pkt{3}{B}\pkt{3}{W}\pkt{3}{B}\pkt{3}{W} & $66.666\dots$ \\
    \bottomrule
  \end{tabular}
  \caption{RLE compression}
  \label{tab:rle-comp}
\end{table}

\subsubsection{Implementation}
\label{sec:implementation-1}

But this is essentially trivial to implement in code. Let us first
consider the compression algorithm, which is shown in algorithm
\ref{alg:rle-enc}. First we need to make sure we have two characrters
to compare for equalirt and possible pack together. So we have the
need of the flag $passedFirstCharacter$ that tells when the first
character has been passed(duh!). Once we have two character then we
can compare then for equality and if they are equal we increase a
counter that keeps tracks of the size of the current packet. If they
are not equal or the current packet is full, we write the
packet. First the length of the packet is written and then the actual
data that is repeated in the package. And the counter is reset and a
new packet is read in.

However, once we have reached the end of the file, we still haven't
written the last packet. But if the file was entiely empty, we'd have
nothing to write, so we need to check that we have passed the first
character. If we have, we simply write the last packet like all the
other packets are written.

\newcommand{\eof}{\ensuremath{\VoidCall{EndOfFileReached}}}
\newcommand{\neof}{\ensuremath{\NOT \VoidCall{EndOfFileReached}}}

\begin{algorithm}[h]
  \caption{Encoding a file using RLE.}
  \label{alg:rle-enc}
  \begin{algorithmic}[1]

    \Let{$length$}{$1$}
    \Let{$passedFirstCharacter$}{\False}
    \Let{$c_2$}{ \VoidCall{ReadByte}}

    \While{\neof}

      \If{$passedFirstCharacter$}
        \If{$c_2 = c_1 \AND length < 255$}
          \Let{$length$}{$1 + length$}
        \Else
          \State \Call{WriteByte}{$length$}
          \State \Call{WriteByte}{$c_1$}
          \Let{$length$}{$1$}
        \EndIf
      \EndIf

      \Let{$passedFirstCharacter$}{\True} %
      \Let{$c_1$}{$c_2$}
      \Let{$c_2$}{ \VoidCall{ReadByte}}

    \EndWhile

    \If{$passedFirstCharacter$} \Comment{Write the last bytes.}
      \State \Call{WriteByte}{$length$}
      \State \Call{WriteByte}{$c_1$}
    \EndIf
  \end{algorithmic}
\end{algorithm}

The ridiculously simple RLE decoding algorithm is shown in algorithm
\ref{alg:rle-dec}

\begin{algorithm}[h]
  \caption{Decoding a RLE encoded file.}
  \label{alg:rle-dec}
  \begin{algorithmic}[1]

    \Let{$length$}{\VoidCall{ReadByte}}
    \Let{$c$}{\VoidCall{ReadByte}}

    \While{\neof}
      \Repeat{$length$}
        \State \Call{WriteByte}{$b$}
      \EndRepeat

      \Let{$length$}{\VoidCall{ReadByte}}
      \Let{$c$}{\VoidCall{ReadByte}}

    \EndWhile
  \end{algorithmic}
\end{algorithm}

While we still haven't reached the end of the file, we read a packet
length and the replicated data number. Once we have done, we simply
write out the data length times.

\subsection{Packets version}
\label{sec:packets-version}

But as previously stated,this algorithm just do horrible on data that
is not at all repetitive, like this:

\begin{indentpar}
  ERICARNE
\end{indentpar}

It will get ``compressed'' down to

\begin{indentpar}
  1E1R1I1C1A1R1N1E
\end{indentpar}

Which is double the size. But we needn't forget that algorithm can
do wonders on data that is actually repetitive like for example

\begin{indentpar}
  WWWWWWWWWWWWAAAAAAAAAAAAAAARRRRRRRRRRRR
\end{indentpar}

So, the question is, can we get rid of potentially doubling the size,
yet still being able to greatly compress data such as the
above. Turns out that we can.

We just need to revise out packet format a tiny bit. A byte could be
written as the following bit pattern

\begin{indentpar}
  $00000000$
\end{indentpar}

Now let us reserve the last bit for a flag, and use the rest
for specifying the size.

\begin{indentpar}
  $\overbrace{0}^ \text{Flag bit}\underbrace{0000000}_ \text{Length bits}$
\end{indentpar}

But this last bit won't of course be wasted, it will specify the type
of the packet. If the value of the it is 1, it will be a raw packet,
elsewhise it will be a run length packet. A run-length packet is just
your ordinary packet we used in the naive version. But however, raw
packet means that the data following the firs byte of the packet is
entirely uncompressed and is a sequence of raw bytes. The length of
this sequence, is the value specified by the first seven bytes. And
the length of a run-length packet is also these seven first
bytes. Hence, the new maximum length of a run length packet is the
maximum number of an unsigned 7-bit number, which is $2^7 -1 = 127$.

So we have lost some valuable storage space, but what did we get in
return? Well, now the string

\begin{indentpar}
  ERICARNE
\end{indentpar}

gets compressed down

\begin{indentpar}
  136ERICARNE
\end{indentpar}

(do remember that 136 is a byte of the value 136, and not the sequence
of the number 1,2 and 6)

Which is a huge gain!

But why is the number so huge? Well, that obviously becuase the last
bit flag in a byte has the value $128$. We can toggle that last flag
like this: $136 \BitXor 128 = 8$. And doing that operation we end up with
the value $8$, which is the length of the raw packet.


And while \textit{not} exploding the size of certain kinds of data,
this algorithms can also reap all the benefits the old naive version
of the algorithm had. So the string

\begin{indentpar}
  WWWWAAAACCCCCC
\end{indentpar}

still gets compressed down to

\begin{indentpar}
  4W4A6C
\end{indentpar}

And all of this in exchange for just one bit!

As an exercise for the reader, examine the following compression and
validate its correctness:

\begin{indentpar}
  EEEEEEERIC
\end{indentpar}

to

\begin{indentpar}
  7E131RIC
\end{indentpar}

Now let's so how we can implement these algorithms. It will be a bit
harder than the naive version, but we will soon find that it is not very
difficult at all!

This algorithm is actually the one used to compress color data in the
TGA image format \cite{91:_truev_tga_file_format_specif}.

\subsubsection{Implementation}
\label{sec:implementation}

\paragraph{Writing the packets}
\label{sec:writing-packets}

Let us first consider how to write a raw packet. Consider the function
\textproc{writeRawPacket}(algorithm \ref{alg:raw-packet}). We'll
call the first byte of a packet the packet head. Making the packet head
is trivial. It is first given an initial value of zero, to specify
that it's a run length packet. Then it's bitwise or-ed with the length
of the packet. After that the entire raw data stream is written to the
file.

And writing a Run Length Packet is even easier! Please observe
algorithm \ref{alg:rle-packet}. Do note that we in this case give the
packet head an initial value of 128. This is because the value of the
last bit in a byte is 128. It is calculated like this: $2^{8-1} =
128$.

\begin{algorithm}[h]
  \caption{Writing a raw packet.}
  \label{alg:raw-packet}
  \begin{algorithmic}[1]
    \Require $length$ is a list or array containing the data to be written
    \Function{writeRawPacket}{$length,data$}
      \Let{$packetHead$}{$0$}
      \Let{$packetHead$}{$packetHead \BitOr length$}
      \State \Call{writeByte}{$packetHead$}
      \ForEach{$raw$}{$data$}
        \State \Call{writeByte}{$raw$}
      \EndForEach
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[h]
  \caption{Writing a run length packet.}
  \label{alg:rle-packet}
  \begin{algorithmic}[1]
    \Require $length > 0$
    \Function{writeRunLengthPacket}{$length,data$}
      \Let{packetHead}{$128$}
      \Let{packetHead}{$packetHead \BitOr length$}
      \State \Call{writeByte}{$packetHead$}
      \State \Call{writeByte}{$data$}
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\paragraph{Compression and decompression.}
\label{sec:compr-decompr}

Now that we know how to write the packets, let us consider how to
implement the algorithm itself. The encoding algorithm can be seen in
algorithm \ref{alg:tga-rle-enc}. This algorithm has a significantly
more complex control flow than algoritms up to this point, so read
carefully.

In the same manner as the naive version, we read in the first two
values. If they are equal, we start writing a run length packet. But
what we have to keep in mind as that we could have been writing raw
packet up to this point. The type of the packet currently being made
is signified by the variable $packetType$. So if a raw packet is being
made, we must finish it by writing it the file. And the counter of the
current package is reset. Otherwise it would not have been reset, as
you could have been writing a run length packet at the time. But why
is only one less of the raw packet length written?

To understand, let us see what happens when the two values are
\textit{not} equal. Then there are two cases to consider again: a run
length packet is being written or a raw packet is being written.

In the first case, we the run length packet is finished och the packet
type is set to raw packet and the counter is reset.

However in the second case, we are writing a raw packet. And so, the
first value is put in the raw packet data array. And the length is
increased. Now it makes sense why one less of the raw packet length is
written, because the length is increase even though the next reas
could result in a run length packet started being written.

\begin{algorithm}[h]
  \caption{Encoding a file using RLE.}
  \label{alg:tga-rle-enc}
  \begin{algorithmic}[1]
    \Require $RawPacket = 0,RunLengthPacket = 1$

    \Let{$length$}{$0$}
    \Let{$passedFirstCharacter$}{\False}
    \Let{$c_2$}{ \VoidCall{ReadByte}}
    \Let{$packetType$}{$RawPacket$}

    \While{\neof}

      \If{$passedFirstCharacter$}
        \If{$c_2 = c_1 \AND length < 127$}

          \If{$packetType = RawPacket \AND length > 0$}
            \State \Call{writeRawPacket}{$length-1,data,out$}
            \Let{$length$}{$0$}
          \EndIf

          \Let{$length$}{$1 + length$}
          \Let{$packetType$}{$RunLengthPacket$}

        \Else

          \If{$packetType = RunLengthPacket$}

            \State \Call{writeRunLengthPacket}{$length,c_1$}
            \Let{$packetType$}{$RawPacket$}
            \Let{$length$}{$0$}

          \Else

            \Let{$data[length]$}{$c_1$}
            \Let{$length$}{$length + 1$}
            \Let{$packetType$}{$RawPacket$}

          \EndIf

        \EndIf
      \EndIf

      \Let{$passedFirstCharacter$}{\True}
      \Let{$c_1$}{$c_2$}
      \Let{$c_2$}{ \VoidCall{ReadByte}}

    \EndWhile

    \If{$passedFirstCharacter$}
      \If{$packetType = RunLengthPacket$}
        \State \Call{$writeRunLengthPacket$}{$length,c_1$}
      \Else
        \Let{$data[length]$}{$c_1$}
        \State \Call{$writeRawLengthPacket$}{$length,data$}
      \EndIf
    \EndIf
  \end{algorithmic}
\end{algorithm}

Phew! Thankfully, the decoding algorithm is not as complex. It can be
seen at algorithm \ref{alg:tga-rle-dec}.

First we read in the packet head of the packet. If the end of the file
has not been reached, we first extract the length out of the packet
head, by using a bitwise and operation on it. This makes sense, as
$127$ has the bit pattern.

\begin{indentpar}
  01111111
\end{indentpar}

Thus, to make sure that we only extract the length part of the head, and
not the highest bit. Then, we check if the highest bit is toggled. If
such is the case, then it's a run length packet. So we read in the
data part of the packet and repeat it $length$ times. Else, it is a
raw packet, and so we just read the data and write it back $length$
times.

\begin{algorithm}[h]
  \caption{Decoding a RLE packbits encoded file.}
  \label{alg:tga-rle-dec}
  \begin{algorithmic}[1]

    \Let{$head$}{\VoidCall{ReadByte}}

    \While{\neof}

      \Let{$length$}{$head \BitAnd 127$}

      \If{$head \BitAnd 128$}
        \Let{$data$}{\VoidCall{ReadByte}}

        \Repeat{$length$}
          \State \Call{WriteByte}{$data$}
        \EndRepeat
      \Else

        \Repeat{$length$}
          \Let{$data$}{\VoidCall{ReadByte}}
          \State \Call{WriteByte}{$data$}
        \EndRepeat

      \EndIf

      \Let{$head$}{\VoidCall{ReadByte}}

    \EndWhile
  \end{algorithmic}
\end{algorithm}

\FloatBarrier

\printbibliography[heading=subbibliography]

\end{refsection}